{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import *\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import easydict\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import six\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.distributed as dist\n",
    "from albumentations import GaussNoise, IAAAdditiveGaussianNoise, Compose, OneOf\n",
    "from albumentations.pytorch import ToTensor\n",
    "import albumentations\n",
    "import cv2\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "# import PositionEnhancement\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset_syllable_180', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset_clf(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, resize_shape = (64, 256), input_channel = 3):\n",
    "        self.dataset = dataset\n",
    "        self.resize_H = resize_shape[0]\n",
    "        self.resize_W = resize_shape[1]\n",
    "        self.transform = albumentations.Compose([\n",
    "            albumentations.RandomBrightnessContrast(p=0.5),\n",
    "            albumentations.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.8, p=0.5 ),\n",
    "            albumentations.Resize(self.resize_H, self.resize_W),\n",
    "            albumentations.Normalize( mean=[0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n",
    "            albumentations.pytorch.transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path, label = self.dataset[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        trans = self.transform(image=image)\n",
    "        image = trans['image']\n",
    "        \n",
    "        return image, len(label)\n",
    "\n",
    "def get_accuracy(pred, label):\n",
    "    pred_max = torch.argmax(torch.softmax(pred, -1), -1)\n",
    "    match = 0\n",
    "    batch_size = pred_max.shape[0]\n",
    "    for i in range(batch_size):\n",
    "        if pred_max[i] == label[i]:\n",
    "            match +=1\n",
    "    return round(match / batch_size, 3)\n",
    "\n",
    "def get_latest_model(name):\n",
    "    relate_models = []\n",
    "    for model_file in os.listdir('./models'):\n",
    "        if re.compile(name).match(model_file):\n",
    "            relate_models.append(int(model_file.split('_')[-1].replace('.pth', '')))\n",
    "    return max(relate_models)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "albu_loader = CustomDataset_clf(data)\n",
    "dataloader = DataLoader(albu_loader, batch_size = 768, shuffle=True, pin_memory=True, num_workers=5, drop_last=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'efficientnet-b0'\n",
    "model = EfficientNet.from_name(name, include_top=True)\n",
    "model._fc = torch.nn.Linear(in_features = 1280, out_features = 23, bias=True)\n",
    "\n",
    "previous_iter = get_latest_model(name)\n",
    "load_path = f'./models/{name}_{previous_iter}.pth'\n",
    "\n",
    "if load_path :\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n",
    "# model = model.to(device)\n",
    "_ = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranable params :  4037011\n"
     ]
    }
   ],
   "source": [
    "# filter that only require gradient descent\n",
    "filtered_parameters = []\n",
    "params_num = []\n",
    "for p in filter(lambda p : p.requires_grad, model.parameters()):\n",
    "    filtered_parameters.append(p)\n",
    "    params_num.append(np.prod(p.size()))\n",
    "print('Tranable params : ', sum(params_num))\n",
    "\n",
    "optimizer = optim.Adadelta(filtered_parameters)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device) #ignore [GO] token = ignore index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (img, label) in enumerate(dataloader):\n",
    "    img, label = img.to(device) , label.to(device)\n",
    "    pred = model(img)\n",
    "    loss = criterion(pred, label)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "    optimizer.step()\n",
    "    \n",
    "    prev_acc=0\n",
    "    if (i % 500 ==0) :\n",
    "#         & (i!=0)\n",
    "        acc = get_accuracy(pred, label)\n",
    "        print(f'{i}th batch, loss : {round(loss.item(), 4)}, last minibatch accuracy : {acc}')\n",
    "        with open('train_log.txt', 'a+') as f:\n",
    "            line = '-'*100 + '\\n'\n",
    "            log = f'{i}th minibatch, last minibatch accuracy : {acc}'\n",
    "            f.write(line + log+'\\n')\n",
    "        if prev_acc < acc:\n",
    "            torch.save(model.module.state_dict(), f'./models/{name}_{previous_iter + i}.pth')\n",
    "            prev_acc = acc\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.module.state_dict(), f'./Nchar_clf_{i}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
