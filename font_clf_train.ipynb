{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.utils.data import *\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "from albumentations import GaussNoise, IAAAdditiveGaussianNoise, Compose, OneOf\n",
    "from albumentations.pytorch import ToTensor\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import gc\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "import json\n",
    "import functools\n",
    "import itertools\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/Data/FoodDetection/AI_OCR')\n",
    "sys.path.append('/home/Data/FoodDetection/AI_OCR/Scatter')\n",
    "sys.path.append('/home/Data/FoodDetection/AI_OCR/Whatiswrong')\n",
    "import augs\n",
    "import utils\n",
    "import www_model_jamo_vertical\n",
    "import ko_dataset\n",
    "from PIL import Image\n",
    "import easydict\n",
    "import pickle\n",
    "import time\n",
    "import re\n",
    "import six\n",
    "import math\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = easydict.EasyDict({\n",
    "    \"experiment_name\" : f'{utils.SaveDir_maker(base_model = \"www_jamo_vertical\", base_model_dir = \"./models\")}',\n",
    "    'saved_model' : '',\n",
    "    \"manualSeed\" : 1111,\n",
    "    \"imgH\" : 32 ,\n",
    "    \"imgW\" :  96,\n",
    "    'batch_size' : 192,\n",
    "    \"PAD\" : True ,\n",
    "    'data_filtering_off' : True,\n",
    "    'workers' : 20,\n",
    "    'rgb' :True,\n",
    "    'sensitive' : True,\n",
    "    'top_char' : ' !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㄲㄸㅃㅆㅉ',\n",
    "    'middle_char' : ' ㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣㅐㅒㅔㅖㅘㅙㅚㅝㅞㅟㅢ',\n",
    "    'bottom_char' : ' ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㄲㄸㅃㅆㅉㄳㄵㄶㄺㄻㄼㄽㄾㄿㅀㅄ',\n",
    "    'lr' : 1,\n",
    "    'rho' : 0.95,\n",
    "    'eps' : 1e-8,\n",
    "    'grad_clip' : 5,\n",
    "    'valInterval' : 5000,\n",
    "    'num_epoch' : 20,\n",
    "    'batch_max_length' : 25,\n",
    "    'num_fiducial' : 20,\n",
    "    'output_channel' : 512,\n",
    "    'hidden_size' :256,\n",
    "    'input_channel' : 3,\n",
    "    'FT' : True,\n",
    "    'extract' : 'RCNN',\n",
    "    'pred' : ''\n",
    "    })\n",
    "\n",
    "\n",
    "top_converter = utils.AttnLabelConverter(opt.top_char)\n",
    "middle_converter = utils.AttnLabelConverter(opt.middle_char)\n",
    "bottom_converter = utils.AttnLabelConverter(opt.bottom_char)\n",
    "opt.top_n_cls = len(top_converter.character)\n",
    "opt.middle_n_cls = len(middle_converter.character)\n",
    "opt.bottom_n_cls = len(bottom_converter.character)\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# classifier = www_model_jamo_vertical.STR(opt, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 426779/2500000 [00:47<03:32, 9754.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough values to unpack (expected 2, got 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500000/2500000 [04:27<00:00, 9331.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892202 files will be loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 688912/892202 [02:51<00:49, 4101.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "담임교사로부터기말시험답안지대리300000가족관계등록부 <- length over 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 892202/892202 [03:45<00:00, 3951.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# # KOREAN\n",
    "# data=[]\n",
    "\n",
    "# ko_synthetic = ko_dataset.korean_synthetic(need_samples = 2500000, mode='jamo')\n",
    "# ko_synthetic_long = ko_dataset.korean_synthetic_long(mode='jamo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data :  3392200\n"
     ]
    }
   ],
   "source": [
    "# # \"\"\" Seed setting \"\"\"\n",
    "# # # print(\"Random Seed: \", opt.manualSeed)\n",
    "# random.seed(opt.manualSeed)\n",
    "# np.random.seed(opt.manualSeed)\n",
    "# torch.manual_seed(opt.manualSeed)\n",
    "# torch.cuda.manual_seed(opt.manualSeed)\n",
    "\n",
    "# data.extend(ko_synthetic.dataset)\n",
    "# data.extend(ko_synthetic_long.dataset)\n",
    "# random.shuffle(data)\n",
    "# print('Total number of data : ', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./synthetic_180', 'wb') as file:\n",
    "#     pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./synthetic_180', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = Compose([\n",
    "                        OneOf([\n",
    "                            augs.GridMask(num_grid=(10,20)),\n",
    "                            augs.RandomAugMix(severity=3, width=3)], p =0.5),\n",
    "                            ToTensor()\n",
    "                       ])\n",
    "train_custom = utils.CustomDataset_jamo(data[ : int(len(data) * 0.98)], resize_shape = (opt.imgH, opt.imgW), transformer=transformers)\n",
    "valid_custom = utils.CustomDataset_jamo(data[ int(len(data) * 0.98): ], resize_shape = (opt.imgH, opt.imgW), transformer=ToTensor())\n",
    "\n",
    "data_loader = DataLoader(train_custom, batch_size = opt.batch_size,  num_workers =15, shuffle=True, drop_last=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_custom, batch_size = opt.batch_size,  num_workers=10, shuffle=True,  drop_last=True, pin_memory=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt):\n",
    "    model = www_model_jamo_vertical.STR(opt, device)\n",
    "    print('model parameters. height {}, width {}, num of fiducial {}, input channel {}, output channel {}, hidden size {}, \\\n",
    "    batch max length {}'.format(opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel, opt.hidden_size, opt.batch_max_length))\n",
    "    \n",
    "    # weight initialization\n",
    "    for name, param, in model.named_parameters():\n",
    "        if 'localization_fc2' in name:\n",
    "            print(f'Skip {name} as it is already initializaed')\n",
    "            continue\n",
    "        try:\n",
    "            if 'bias' in name:\n",
    "                init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                init.kaiming_normal_(param)\n",
    "                \n",
    "        except Exception as e :\n",
    "            if 'weight' in name:\n",
    "                param.data.fill_(1)\n",
    "            continue\n",
    "            \n",
    "    # load pretrained model\n",
    "    if opt.saved_model != '':\n",
    "        base_path = './models'\n",
    "        print(f'looking for pretrained model from {os.path.join(base_path, opt.saved_model)}')\n",
    "        \n",
    "        try :\n",
    "            model.load_state_dict(torch.load(os.path.join(base_path, opt.saved_model)))\n",
    "            print('loading complete ')    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('coud not find model')\n",
    "            \n",
    "    #data parallel for multi GPU\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "    model.train() \n",
    "     \n",
    "    # loss\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device) #ignore [GO] token = ignore index 0\n",
    "    log_avg = utils.Averager()\n",
    "    \n",
    "    # filter that only require gradient descent\n",
    "    filtered_parameters = []\n",
    "    params_num = []\n",
    "    for p in filter(lambda p : p.requires_grad, model.parameters()):\n",
    "        filtered_parameters.append(p)\n",
    "        params_num.append(np.prod(p.size()))\n",
    "    print('Tranable params : ', sum(params_num))\n",
    "    \n",
    "    # optimizer\n",
    "    \n",
    "#     base_opt = optim.Adadelta(filtered_parameters, lr= opt.lr, rho = opt.rho, eps = opt.eps)\n",
    "#     base_opt = torch.optim.Adam(filtered_parameters, lr=0.0001)\n",
    "#     optimizer = SWA(base_opt)\n",
    "    optimizer = torch.optim.AdamW(filtered_parameters)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', verbose=True, patience = 2, factor= 0.5 )\n",
    "#     optimizer = adabound.AdaBound(filtered_parameters, lr=1e-3, final_lr=0.1)\n",
    "    \n",
    "    # opt log\n",
    "    with open(f'./models/{opt.experiment_name}/opt.txt', 'a') as opt_file:\n",
    "        opt_log = '---------------------Options-----------------\\n'\n",
    "        args = vars(opt)\n",
    "        for k, v in args.items():\n",
    "            opt_log +=f'{str(k)} : {str(v)}\\n'\n",
    "        opt_log +='---------------------------------------------\\n'\n",
    "        opt_file.write(opt_log)\n",
    "        \n",
    "    #start training\n",
    "    start_time = time.time()\n",
    "    best_accuracy = -1\n",
    "    best_norm_ED = -1\n",
    "    swa_count = 0\n",
    "    \n",
    "    for n_epoch, epoch in enumerate(range(opt.num_epoch)):\n",
    "        for n_iter, data_point in enumerate(data_loader):\n",
    "            \n",
    "            image_tensors, top, mid, bot = data_point \n",
    "\n",
    "            image = image_tensors.to(device)\n",
    "            text_top, length_top = top_converter.encode(top, batch_max_length = opt.batch_max_length)\n",
    "            text_mid, length_mid = middle_converter.encode(mid, batch_max_length = opt.batch_max_length)\n",
    "            text_bot, length_bot = bottom_converter.encode(bot, batch_max_length = opt.batch_max_length)\n",
    "            batch_size = image.size(0)\n",
    "          \n",
    "            pred_top, pred_mid, pred_bot = model(image, text_top[:,:-1], text_mid[:,:-1], text_bot[:,:-1])\n",
    "            \n",
    "#             cost_top = criterion(pred_top.view(-1, pred_top.shape[-1]), text_top[:, 1:].contiguous().view(-1))\n",
    "#             cost_mid = criterion(pred_mid.view(-1, pred_mid.shape[-1]), text_mid[:, 1:].contiguous().view(-1))\n",
    "#             cost_bot = criterion(pred_bot.view(-1, pred_bot.shape[-1]), text_bot[:, 1:].contiguous().view(-1))\n",
    "        \n",
    "            cost_top = utils.reduced_focal_loss(pred_top.view(-1, pred_top.shape[-1]), text_top[:, 1:].contiguous().view(-1), gamma=2, alpha=0.25, threshold=0.5)\n",
    "            cost_mid = utils.reduced_focal_loss(pred_mid.view(-1, pred_mid.shape[-1]), text_mid[:, 1:].contiguous().view(-1), gamma=2, alpha=0.25, threshold=0.5)\n",
    "            cost_bot = utils.reduced_focal_loss(pred_bot.view(-1, pred_bot.shape[-1]), text_bot[:, 1:].contiguous().view(-1), gamma=2, alpha=0.25, threshold=0.5)\n",
    "            \n",
    "#             cost_top = utils.CB_loss(text_top[:, 1:].contiguous().view(-1), pred_top.view(-1, pred_top.shape[-1]), top_per_cls, opt.top_n_cls, 'focal', 0.99, 2)\n",
    "#             cost_mid = utils.CB_loss(text_mid[:, 1:].contiguous().view(-1), pred_mid.view(-1, pred_mid.shape[-1]), mid_per_cls, opt.middle_n_cls, 'focal', 0.99, 2)\n",
    "#             cost_bot = utils.CB_loss(text_bot[:, 1:].contiguous().view(-1), pred_bot.view(-1, pred_bot.shape[-1]), bot_per_cls, opt.bottom_n_cls, 'focal', 0.99, 2)\n",
    "            cost = cost_top + cost_mid + cost_bot\n",
    "    \n",
    "            loss_avg = utils.Averager()\n",
    "            loss_avg.add(cost)\n",
    "            \n",
    "            model.zero_grad()\n",
    "            cost.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip) #gradient clipping with 5\n",
    "            optimizer.step()\n",
    "#             print(loss_avg.val())\n",
    "\n",
    "            #validation\n",
    "            if (n_iter % opt.valInterval == 0)& (n_iter!=0) :\n",
    "                elapsed_time = time.time() - start_time\n",
    "                with open(f'./models/{opt.experiment_name}/log_train.txt', 'a') as log:\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        valid_loss, current_accuracy, current_norm_ED, pred_top_str, pred_mid_str, pred_bot_str, label_top, label_mid, label_bot, infer_time, length_of_data = evaluate.validation_jamo(model, criterion, valid_loader, top_converter, middle_converter, bottom_converter, opt)\n",
    "                    scheduler.step(current_accuracy)\n",
    "                    model.train()\n",
    "\n",
    "                    present_time = time.localtime()\n",
    "                    loss_log = f'[epoch : {n_epoch}/{opt.num_epoch}] [iter : {n_iter*opt.batch_size} / {int(len(data) * 0.95)}]\\n'+\\\n",
    "                    f'Train loss : {loss_avg.val():0.5f}, Valid loss : {valid_loss:0.5f}, Elapsed time : {elapsed_time:0.5f}, Present time : {present_time[1]}/{present_time[2]}, {present_time[3]+9} : {present_time[4]}'\n",
    "                    loss_avg.reset()\n",
    "\n",
    "                    current_model_log = f'{\"Current_accuracy\":17s}: {current_accuracy:0.3f}, {\"current_norm_ED\":17s}: {current_norm_ED:0.2f}'\n",
    "\n",
    "                    #keep the best\n",
    "                    if current_accuracy > best_accuracy:\n",
    "                        best_accuracy = current_accuracy\n",
    "                        torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/best_accuracy_{round(current_accuracy,2)}.pth')\n",
    "\n",
    "                    if current_norm_ED > best_norm_ED:\n",
    "                        best_norm_ED = current_norm_ED\n",
    "                        torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/best_norm_ED.pth')\n",
    "\n",
    "                    best_model_log = f'{\"Best accuracy\":17s}: {best_accuracy:0.3f}, {\"Best_norm_ED\":17s}: {best_norm_ED:0.2f}'\n",
    "                    loss_model_log = f'{loss_log}\\n{current_model_log}\\n{best_model_log}'\n",
    "                    print(loss_model_log)\n",
    "                    log.write(loss_model_log+'\\n')\n",
    "\n",
    "                    dashed_line = '-'*80\n",
    "                    head = f'{\"Ground Truth\":25s} | {\"Prediction\" :25s}| T/F'\n",
    "                    predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
    "\n",
    "                    random_idx  = np.random.choice(range(len(label_top)), size= 5, replace=False)\n",
    "                    label_concat = np.concatenate([np.asarray(label_top).reshape(1,-1), np.asarray(label_mid).reshape(1,-1), np.asarray(label_bot).reshape(1,-1)], axis=0).reshape(3,-1)\n",
    "                    pred_concat = np.concatenate([np.asarray(pred_top_str).reshape(1,-1), np.asarray(pred_mid_str).reshape(1,-1), np.asarray(pred_bot_str).reshape(1,-1)], axis=0).reshape(3,-1)\n",
    "                    \n",
    "                    for i in random_idx:\n",
    "                        label_sample = label_concat[:, i]\n",
    "                        pred_sample = pred_concat[:, i]\n",
    "\n",
    "                        gt_str = utils.str_combine(label_sample[0], label_sample[1], label_sample[2])\n",
    "                        pred_str = utils.str_combine(pred_sample[0], pred_sample[1], pred_sample[2])\n",
    "                        predicted_result_log += f'{gt_str:25s} | {pred_str:25s} | \\t{str(pred_str == gt_str)}\\n'\n",
    "                    predicted_result_log += f'{dashed_line}'\n",
    "                    print(predicted_result_log)\n",
    "                    log.write(predicted_result_log+'\\n')\n",
    "                    \n",
    "                # Stochastic weight averaging\n",
    "#                 optimizer.update_swa()\n",
    "#                 swa_count+=1\n",
    "#                 if swa_count % 3 ==0:\n",
    "#                     optimizer.swap_swa_sgd()\n",
    "#                     torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/swa_{swa_count}.pth')\n",
    "\n",
    "        if (n_epoch) % 5 ==0:\n",
    "            torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/{n_epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model parameters. height 32, width 96, num of fiducial 20, input channel 3, output channel 512, hidden size 256,     batch max length 25\n",
      "Skip Trans.LocalizationNetwork.localization_fc2.weight as it is already initializaed\n",
      "Skip Trans.LocalizationNetwork.localization_fc2.bias as it is already initializaed\n",
      "Tranable params :  8734485\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(f'./models/{opt.experiment_name}', exist_ok=True)\n",
    "\n",
    "# set GPU\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = True\n",
    "opt.num_gpu = torch.cuda.device_count()\n",
    "\n",
    "train(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
