{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.5.0+cu101 in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
      "Requirement already satisfied: torchvision==0.6.0+cu101 in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0+cu101) (0.17.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0+cu101) (1.16.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.0+cu101) (6.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "filedescriptor out of range in select()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e421a74f1aca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' pip install easydict jamo tqdm pillow lmdb natsort nltk adabound'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2444\u001b[0m         \u001b[0;31m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m         \u001b[0;31m# Instead, we store the exit_code in user_ns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;31m# res is the index of the pattern that caused the match, so we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;31m# know whether we've finished (if we matched EOF) or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0mres_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;31m# Still have time left, so read more data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mread_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;31m# * https://github.com/pexpect/pexpect/pull/304\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# * http://trac.sagemath.org/ticket/10295\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mselect_ignore_interrupts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild_fd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;31m# If there is data available to read right now, read as much as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/utils.py\u001b[0m in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miwtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: filedescriptor out of range in select()"
     ]
    }
   ],
   "source": [
    "! pip install easydict jamo tqdm pillow lmdb natsort nltk adabound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import PIL as pil\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import easydict\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import six\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils import AttnLabelConverter, Averager, AlignCollate\n",
    "import utils\n",
    "import Trans\n",
    "import Extract\n",
    "from Seq import BidirectionalLSTM\n",
    "import Seq\n",
    "import Pred\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import *\n",
    "from jamo import h2j, j2hcj\n",
    "import gc\n",
    "import adabound\n",
    "import torch.distributed as dist\n",
    "# from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "def json_loader(path):\n",
    "    with open(path, 'r') as json_file:\n",
    "        file = json.load(json_file)\n",
    "    return file\n",
    "\n",
    "def img_annot_split(label):\n",
    "    label_images = pd.DataFrame(label['images'])\n",
    "    label_annot = pd.DataFrame(label['annotations'])\n",
    "    return label_images, label_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Trans' from '/Data/FoodDetection/AI_OCR/Trans.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(Trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arguements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt\n",
    "opt = easydict.EasyDict({\n",
    "    \"experiment_name\" : 'second_0527',\n",
    "    \"manualSeed\" : 1111,\n",
    "    \"imgH\" : 35 ,\n",
    "    \"imgW\" :  90,\n",
    "    \"PAD\" : True ,\n",
    "    'batch_size' : 384,\n",
    "    'data_filtering_off' : True,\n",
    "    'workers' : 20,\n",
    "    'rgb' :True,\n",
    "    'sensitive' : True,\n",
    "    'character' : '0123456789ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎㄵㄶㄺㄻㅀㄼㅄㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣㅐㅒㅔㅖㅢㅟㅝㅞㅚㅘㅙ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~' ,\n",
    "    'batch_max_length' : 25,\n",
    "    'num_fiducial' : 20,\n",
    "    'output_channel' : 512,\n",
    "    'hidden_size' :256,\n",
    "    'lr' : 1,\n",
    "    'rho' : 0.95,\n",
    "    'eps' : 1e-8,\n",
    "    'grad_clip' : 5,\n",
    "    'valInterval' : 100,\n",
    "    'num_epoch' : 30000,\n",
    "    'input_channel' : 3,\n",
    "    'saved_model' : 'second_0527/best_accuracy.pth',\n",
    "    'FT' : True\n",
    "    })\n",
    "\n",
    "device = torch.device('cuda') #utils.py 안에 device는 따로 세팅해줘야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359997/359997 [00:21<00:00, 16700.77it/s]\n"
     ]
    }
   ],
   "source": [
    "base_path = '/Data/KoreanSTR/'\n",
    "\n",
    "# path_wild = '/Data/KoreanSTR/textinthewild_data_info.json'\n",
    "# path_printed = '/Data/KoreanSTR/printed_data_info.json'\n",
    "path_hand = '/Data/KoreanSTR/handwriting_data_info1.json'\n",
    "# path_aug = '/Data/KoreanSTR/augmentation_data_info.json'\n",
    "\n",
    "label_hand = json_loader(path_hand)\n",
    "label_hand_images, label_hand_annot = img_annot_split(label_hand)\n",
    "\n",
    "label_hand_annot = label_hand_annot[['id','text']]\n",
    "\n",
    "dataset = '1_word'\n",
    "file_list_word = os.listdir(os.path.join(base_path, dataset))\n",
    "files_word = pd.DataFrame(file_list_word, columns=['file_name'])\n",
    "files_word['id'] = files_word['file_name'].apply(lambda x : x.replace('.png',''))\n",
    "files_labels = pd.merge(files_word, label_hand_annot, how='left', left_on='id',right_on='id' )\n",
    "\n",
    "word_data = []\n",
    "# random_idx = np.random.choice(range(len(files_labels)), size= int(len(files_labels) * 1), replace=False)\n",
    "for file in tqdm(files_labels['file_name']):\n",
    "#     img_arr = np.asarray(Image.open(os.path.join(base_path, dataset, file)))\n",
    "    img_arr = Image.open(os.path.join(base_path, dataset, file))\n",
    "    word_data.append(img_arr)\n",
    "    \n",
    "labels = [j2hcj(h2j(x)) for x in files_labels['text']]\n",
    "\n",
    "dataset = []\n",
    "for img, text in zip(word_data, labels):\n",
    "    dataset.append((img, text))\n",
    "    \n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice, cycle\n",
    "\n",
    "class Dataset_streamer(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, transformer=None):\n",
    "        self.dataset = dataset\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        \n",
    "#     def __iter__(self):\n",
    "#         return cycle(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.transformer:\n",
    "            return (self.transformer(self.dataset[idx][0]), self.dataset[idx][1])\n",
    "        \n",
    "        else:\n",
    "            return self.dataset[idx]\n",
    "                    \n",
    "    \n",
    "transform = transforms.Compose([transforms.ColorJitter(brightness=0.2, contrast=0.3),\n",
    "                                transforms.RandomAffine(degrees= 50,shear=45),\n",
    "                                transforms.RandomPerspective(distortion_scale=0.3, p=0.7, interpolation=3, fill=0)])\n",
    "\n",
    "dataset_streamer = Dataset_streamer(dataset[ : int(len(dataset)*0.9)], transform)\n",
    "valid_streamer = Dataset_streamer(dataset[int(len(dataset)*0.9) : ], transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_AlignCollate = utils.AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=True)\n",
    "data_loader = DataLoader(dataset_streamer, batch_size = opt.batch_size,  num_workers =0, shuffle=True, #worker_init_fn=worker_init_fn, \n",
    "                         collate_fn = _AlignCollate, pin_memory=False )\n",
    "data_loader_iter = iter(data_loader)\n",
    "\n",
    "#for valid\n",
    "_AlignCollate_valid = utils.AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=True)\n",
    "#not valid_streamer\n",
    "valid_loader = DataLoader(valid_streamer, batch_size = opt.batch_size,  num_workers=0, shuffle=True, #worker_init_fn = worker_init_fn,\n",
    "                          collate_fn=_AlignCollate_valid, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img, label = next(data_loader_iter)\n",
    "# valid_iter = iter(valid_loader)\n",
    "# img, label = valid_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅎㅏㅁㄲㅔㅎㅏㄷㅏ\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = np.random.choice(range(opt.batch_size),size=1)[0]\n",
    "plt.imshow(img[random_idx].numpy()[0])\n",
    "print(label[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359997"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTN(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(CTN, self).__init__()\n",
    "        self.opt = opt\n",
    "        \n",
    "        #Trans\n",
    "        self.Trans = Trans.TPS_SpatialTransformerNetwork(F = opt.num_fiducial,\n",
    "                                                  i_size = (opt.imgH, opt.imgW), \n",
    "                                                  i_r_size= (opt.imgH, opt.imgW), \n",
    "                                                  i_channel_num=opt.input_channel,\n",
    "                                                        device = device)\n",
    "        #Extract\n",
    "        self.Extract = Extract.RCNN_extractor(opt.input_channel, opt.output_channel)\n",
    "        self.FeatureExtraction_output = opt.output_channel # (imgH/16 -1 )* 512\n",
    "        self.AdaptiveAvgPool = nn.AdaptiveAvgPool2d((None,1)) # imgH/16-1   ->  1\n",
    "#         self.Extract = EfficientNet()\n",
    "        \n",
    "        \n",
    "         \n",
    "        # Sequence\n",
    "        self.Seq = nn.Sequential(\n",
    "            BidirectionalLSTM(self.FeatureExtraction_output, opt.hidden_size,  opt.hidden_size),\n",
    "#             BidirectionalLSTM(1536, opt.hidden_size,  opt.hidden_size),\n",
    "            BidirectionalLSTM(opt.hidden_size, opt.hidden_size, opt.hidden_size))\n",
    "        self.Seq_output = opt.hidden_size\n",
    "        \n",
    "        #Pred\n",
    "        self.Pred = Pred.Attention(self.Seq_output, opt.hidden_size, opt.num_class, device=device)\n",
    "        \n",
    "        \n",
    "    def forward(self, input, text, is_train=True):\n",
    "        #Trans stage\n",
    "        input = self.Trans(input)\n",
    "        \n",
    "        #Extract stage\n",
    "        visual_feature = self.Extract(input)\n",
    "        visual_feature = self.AdaptiveAvgPool(visual_feature.permute(0, 3, 1, 2))\n",
    "        visual_feature = visual_feature.squeeze(3)\n",
    "        \n",
    "        #Seq stage\n",
    "        contextual_feature = self.Seq(visual_feature)\n",
    "        #Pred stage\n",
    "        prediction = self.Pred(contextual_feature.contiguous(), text, is_train, batch_max_length = self.opt.batch_max_length)\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt):\n",
    "    converter = AttnLabelConverter(opt.character)\n",
    "    opt.num_class = len(converter.character)\n",
    "    \n",
    "    model = CTN(opt)\n",
    "    print('model parameters. height {}, width {}, num of fiducial {}, input channel {}, output channel {}, hidden size {}, num class {},\\\n",
    "    batch max length {}'.format(opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel, opt.hidden_size, opt.num_class,\n",
    "                               opt.batch_max_length))\n",
    "    \n",
    "    # weight initialization\n",
    "    for name, param, in model.named_parameters():\n",
    "        if 'localization_fc2' in name:\n",
    "            print(f'Skip {name} as it is already initializaed')\n",
    "            continue\n",
    "        try:\n",
    "            if 'bias' in name:\n",
    "                init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                init.kaiming_normal_(param)\n",
    "                \n",
    "        except Exception as e :\n",
    "            if 'weight' in name:\n",
    "                param.data.fill_(1)\n",
    "            continue\n",
    "            \n",
    "    #data parallel for multi GPU\n",
    "    model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n",
    "#     model = model.to(device)\n",
    "    model.train() \n",
    "    \n",
    "    if opt.saved_model != '':\n",
    "        base_path = './models'\n",
    "        print(f'looking for pretrained model from {os.path.join(base_path, opt.saved_model)}')\n",
    "        \n",
    "        try :\n",
    "            if opt.FT:\n",
    "                model.load_state_dict(torch.load(os.path.join(base_path, opt.saved_model)), strict=False)\n",
    "            else:\n",
    "                model.load_state_dict(torch.load(os.path.join(base_path, opt.saved_model)))\n",
    "            print('loading complete')    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('coud not find model')\n",
    "        \n",
    "     \n",
    "    # loss\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device) #ignore [GO] token = ignore index 0\n",
    "    log_avg = Averager()\n",
    "    \n",
    "    # filter that only require gradient descent\n",
    "    filtered_parameters = []\n",
    "    params_num = []\n",
    "    for p in filter(lambda p : p.requires_grad, model.parameters()):\n",
    "        filtered_parameters.append(p)\n",
    "        params_num.append(np.prod(p.size()))\n",
    "    print('Tranable params : ', sum(params_num))\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = optim.Adadelta(filtered_parameters, lr= opt.lr, rho = opt.rho, eps = opt.eps)\n",
    "#     optimizer = adabound.AdaBound(filtered_parameters, lr=1e-3, final_lr=0.1)\n",
    "    \n",
    "    # opt log\n",
    "    with open(f'./models/{opt.experiment_name}/opt.txt', 'a') as opt_file:\n",
    "        opt_log = '---------------------Options-----------------\\n'\n",
    "        args = vars(opt)\n",
    "        for k, v in args.items():\n",
    "            opt_log +=f'{str(k)} : {str(v)}\\n'\n",
    "        opt_log +='---------------------------------------------\\n'\n",
    "        opt_file.write(opt_log)\n",
    "        \n",
    "    #start training\n",
    "    start_iter = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    best_accuracy = -1\n",
    "    best_norm_ED = -1\n",
    "\n",
    "    \n",
    "    \n",
    "    for n_epoch, epoch in enumerate(range(opt.num_epoch)):\n",
    "        for n_iter, data_point in enumerate(data_loader):\n",
    "            image_tensors, labels = data_point\n",
    "            \n",
    "            \n",
    "#     while(True):\n",
    "#         image_tensors, labels = data_loader_iter.next()\n",
    "            image = image_tensors.to(device)\n",
    "            text, length = converter.encode(labels, batch_max_length = opt.batch_max_length)\n",
    "\n",
    "            batch_size = image.size(0)\n",
    "\n",
    "\n",
    "            preds = model(image, text[:, : -1])\n",
    "            target = text[:, 1:]\n",
    "            cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "\n",
    "            loss_avg = Averager()\n",
    "\n",
    "            model.zero_grad()\n",
    "            cost.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip) #gradient clipping with 5\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_avg.add(cost)\n",
    "\n",
    "            #validation\n",
    "            if n_iter % opt.valInterval == 0:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                with open(f'./models/{opt.experiment_name}/log_train.txt', 'a') as log:\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        valid_loss, current_accuracy, current_norm_ED, preds, confidence_score, labels, infer_time, length_of_data = utils.validation(\n",
    "                            model, criterion, valid_loader, converter, opt)\n",
    "                    model.train()\n",
    "                    \n",
    "                    present_time = time.localtime()\n",
    "                    loss_log = f'[epoch : {n_epoch}/{opt.num_epoch}] [iter : {n_iter*opt.batch_size} / {len(dataset)}]\\n'+\\\n",
    "                    f'Train loss : {loss_avg.val():0.5f}, Valid loss : {valid_loss:0.5f}, Elapsed time : {elapsed_time:0.5f}, Present time : {present_time[1]}/{present_time[2]}, {present_time[3]+9} : {present_time[4]}'\n",
    "                    loss_avg.reset()\n",
    "\n",
    "                    current_model_log = f'{\"Current_accuracy\":17s}: {current_accuracy:0.3f}, {\"current_norm_ED\":17s}: {current_norm_ED:0.2f}'\n",
    "\n",
    "\n",
    "                    #keep the best\n",
    "                    if current_accuracy > best_accuracy:\n",
    "                        best_accuracy = current_accuracy\n",
    "                        torch.save(model.state_dict(), f'./models/{opt.experiment_name}/best_accuracy.pth')\n",
    "\n",
    "                    if current_norm_ED > best_norm_ED:\n",
    "                        best_norm_ED = current_norm_ED\n",
    "                        torch.save(model.state_dict(), f'./models/{opt.experiment_name}/best_norm_ED.pth')\n",
    "\n",
    "                    best_model_log = f'{\"Best accuracy\":17s}: {best_accuracy:0.3f}, {\"Best_norm_ED\":17s}: {best_norm_ED:0.2f}'\n",
    "                    loss_model_log = f'{loss_log}\\n{current_model_log}\\n{best_model_log}'\n",
    "                    print(loss_model_log)\n",
    "                    log.write(loss_model_log+'\\n')\n",
    "\n",
    "\n",
    "                    dashed_line = '-'*80\n",
    "                    head = f'{\"Ground Truth\":25s} | {\"Prediction\" :25s}| Confidence Score & T/F'\n",
    "                    predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
    "\n",
    "                    random_idx  = np.random.choice(range(len(labels)), size= 5, replace=False)\n",
    "                    for gt, pred, confidence in zip(list(np.asarray(labels)[random_idx]), list(np.asarray(preds)[random_idx]), list(np.asarray(confidence_score)[random_idx])):\n",
    "    #                     if 'Attn' in opt.Prediction:\n",
    "                        gt = gt[: gt.find('[s]')]\n",
    "                        pred = pred[: pred.find('[s]')]\n",
    "\n",
    "                        predicted_result_log += f'{gt:25s} | {pred:25s} | {confidence:0.4f}\\t{str(pred == gt)}\\n'\n",
    "                    predicted_result_log += f'{dashed_line}'\n",
    "                    print(predicted_result_log)\n",
    "                    log.write(predicted_result_log+'\\n')\n",
    "\n",
    "            if (n_epoch)% 10 ==0:\n",
    "                torch.save(model.state_dict(), f'./models/{opt.experiment_name}/{n_epoch}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Use multi GPU setting --------\n",
      "model parameters. height 35, width 90, num of fiducial 20, input channel 3, output channel 512, hidden size 256, num class 91,    batch max length 25\n",
      "Skip Trans.LocalizationNetwork.localization_fc2.weight as it is already initializaed\n",
      "Skip Trans.LocalizationNetwork.localization_fc2.bias as it is already initializaed\n",
      "looking for pretrained model from ./models/second_0527/best_accuracy.pth\n",
      "loading complete\n",
      "Tranable params :  7221443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 0/30000] [iter : 0 / 359997]\n",
      "Train loss : 3.33227, Valid loss : 11.06066, Elapsed time : 8.89035, Present time : 5/27, 14 : 17\n",
      "Current_accuracy : 1.028, current_norm_ED  : 0.20\n",
      "Best accuracy    : 1.028, Best_norm_ED     : 0.20\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅁㅗㅇㅕㄷㅡㄹㄷㅏ                 | ㅁㅜㅇㅢㅁㅣㅅㅡ                  | 0.0255\tFalse\n",
      "ㅊㅏㄴㅁㅜㄹ                    | ㅇㅓㅂㄹㅕㄱㅎㅏㄷㅏ                | 0.1471\tFalse\n",
      "ㅅㅣㄱㅏㄱ                     | ㅇㅛㄱㅜㄷㅚㄷㅏ                  | 0.1883\tFalse\n",
      "ㅂㅐㅊㅣ                      | ㅇㅏㄴㅈㅓㄴㄷㅚㄷㅏ                | 0.0440\tFalse\n",
      "ㅈㅓㅇㅊㅣㅎㅏㄱ                  | ㅇㅗㅇㅕㅁㄷㅚㄷㅏ                 | 0.0405\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 0/30000] [iter : 100 / 359997]\n",
      "Train loss : 0.67628, Valid loss : 4.83427, Elapsed time : 892.65698, Present time : 5/27, 14 : 31\n",
      "Current_accuracy : 30.828, current_norm_ED  : 0.55\n",
      "Best accuracy    : 30.828, Best_norm_ED     : 0.55\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅈㅏㅇㄴㅏㅁ                    | ㅈㅏㅇㄴㅏㅁ                    | 0.4536\tTrue\n",
      "ㅇㅟㄷㅐㅎㅏㄷㅏ                  | ㅁㅜㄷㅐㅁㅇㅣㅁㅎㅏㄷㅏ              | 0.2094\tFalse\n",
      "ㄷㅔㄹㅕㄱㅏㄷㅏ                  | ㄸㅓㄹㅇㅓㅈㅣㄷㅏ                 | 0.2943\tFalse\n",
      "ㅊㅣㅁㅏ                      | ㅊㅣㅇㅏ                      | 0.2761\tFalse\n",
      "ㅊㅜㄹㅅㅣㄴ                    | ㅊㅜㄹㅅㅣㄴ                    | 0.6712\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 0/30000] [iter : 200 / 359997]\n",
      "Train loss : 0.47429, Valid loss : 4.20857, Elapsed time : 1734.10382, Present time : 5/27, 14 : 45\n",
      "Current_accuracy : 37.558, current_norm_ED  : 0.61\n",
      "Best accuracy    : 37.558, Best_norm_ED     : 0.61\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅇㅓㅉㅓㅁ                     | ㅇㅓㄹㅕㄴ                     | 0.0290\tFalse\n",
      "ㅁㅏㄹㄷㅏ                     | ㅁㅏㄹㄷㅏ                     | 0.7824\tTrue\n",
      "ㅇㅚㅊㅣㄷㅏ                    | ㅇㅚㅊㅣㄷㅏ                    | 0.9107\tTrue\n",
      "ㄹㅏㅁㅕㄴ                     | ㅈㅏㅇㅂㅣ                     | 0.0647\tFalse\n",
      "ㅇㅕㄴㅎㅏㅂ                    | ㅇㅕㄴㄹㅏㄱ                    | 0.0739\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 0/30000] [iter : 300 / 359997]\n",
      "Train loss : 0.39776, Valid loss : 3.38131, Elapsed time : 2573.94818, Present time : 5/27, 14 : 59\n",
      "Current_accuracy : 47.342, current_norm_ED  : 0.69\n",
      "Best accuracy    : 47.342, Best_norm_ED     : 0.69\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅅㅔㄴㅌㅣㅁㅣㅌㅓ                 | ㅅㅗㅇㅛㅇㅇㅓㅄㄷㅏ                | 0.0057\tFalse\n",
      "ㅇㅣㄹㄷㅡㅇ                    | ㅇㅣㄹㄷㅡㅇ                    | 0.4674\tTrue\n",
      "ㅇㅓㄱ                       | ㅁㅏㅅ                       | 0.0577\tFalse\n",
      "ㄷㅟ                        | ㄷㅟ                        | 0.9927\tTrue\n",
      "ㅇㅓㅇㄷㅓㅇㅇㅣ                  | ㅇㅓㅉㅣㄴㅏ                    | 0.0106\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 0/30000] [iter : 400 / 359997]\n",
      "Train loss : 0.35233, Valid loss : 3.20411, Elapsed time : 3420.75733, Present time : 5/27, 15 : 13\n",
      "Current_accuracy : 50.456, current_norm_ED  : 0.72\n",
      "Best accuracy    : 50.456, Best_norm_ED     : 0.72\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㄱㅐㅅㅓㄴㅎㅏㄷㅏ                 | ㄱㅐㅂㅏㅇㅎㅏㄷㅏ                 | 0.3268\tFalse\n",
      "ㅇㅚㅈㅔ                      | ㅇㅗㅅㅣㅂ                     | 0.0210\tFalse\n",
      "ㅂㅜㄹ                       | ㅂㅜㄱ                       | 0.8909\tFalse\n",
      "ㅌㅏㄴㅅㅐㅇㅎㅏㄷㅏ                | ㄷㅏㄴㅅㅜㄴㅎㅏㄷㅏ                | 0.4787\tFalse\n",
      "ㅇㅣㄹㅓㄴ                     | ㅇㅣㄹㅓㄴ                     | 0.9517\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 0/30000] [iter : 500 / 359997]\n",
      "Train loss : 0.25387, Valid loss : 2.65967, Elapsed time : 4273.36708, Present time : 5/27, 15 : 27\n",
      "Current_accuracy : 57.828, current_norm_ED  : 0.77\n",
      "Best accuracy    : 57.828, Best_norm_ED     : 0.77\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅈㅓㄴㅕㄱ                     | ㅈㅓㄴㅕㄱ                     | 0.9100\tTrue\n",
      "ㅈㅜㄴㅕㄴ                     | ㅈㅓㅇㅊㅣ                     | 0.0199\tFalse\n",
      "ㅈㅜㄴㅕㄴ                     | ㅈㅜㄴㅕㄴ                     | 0.9770\tTrue\n",
      "ㄸㅏㄱ                       | ㅍㅏㄹ                       | 0.7598\tFalse\n",
      "ㅇㅚㄹㅗㅂㄷㅏ                   | ㅇㅚㄹㅗㅂㄷㅏ                   | 0.6077\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 0/30000] [iter : 600 / 359997]\n",
      "Train loss : 0.24926, Valid loss : 2.71614, Elapsed time : 5126.57720, Present time : 5/27, 15 : 41\n",
      "Current_accuracy : 57.433, current_norm_ED  : 0.77\n",
      "Best accuracy    : 57.828, Best_norm_ED     : 0.77\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㄴㅡㄹ                       | ㄴㅡㄹ                       | 0.8216\tTrue\n",
      "ㅎㅐㄹㅗㅂㄷㅏ                   | ㅎㅐㄹㅗㅂㄷㅏ                   | 0.4925\tTrue\n",
      "ㅅㅏㄹㅣㅂ                     | ㅅㅣㅇㅟ                      | 0.2287\tFalse\n",
      "ㄴㅏㄱㅏㄷㅏ                    | ㄴㅏㄱㅏㄷㅏ                    | 0.7319\tTrue\n",
      "ㅇㅚㅊㅣㄷㅏ                    | ㅇㅚㅊㅣㄷㅏ                    | 0.3207\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 0/30000] [iter : 700 / 359997]\n",
      "Train loss : 0.21222, Valid loss : 3.12995, Elapsed time : 5988.35360, Present time : 5/27, 15 : 56\n",
      "Current_accuracy : 50.700, current_norm_ED  : 0.72\n",
      "Best accuracy    : 57.828, Best_norm_ED     : 0.77\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㄴㅏㄹㅇㅏㄱㅏㄷㅏ                 | ㄴㅏㄹㅇㅏㄱㅏㄷㅏ                 | 0.9265\tTrue\n",
      "ㅊㅚㄱㅗㄱㅡㅂ                   | ㅊㅚㄱㅗㄱㅡㅂ                   | 0.9540\tTrue\n",
      "ㄱㅏㅁㄱㅣ                     | ㄱㅏㅁㄱㅣ                     | 0.9207\tTrue\n",
      "ㅁㅣㄴㅅㅗㄱ                    | ㅁㅣㄴㅅㅗㄱ                    | 0.9692\tTrue\n",
      "ㅈㅓㄹㄷㅐㄹㅗ                   | ㅅㅓㄹㄷㅏㅇㅜㄱ                  | 0.0588\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 0/30000] [iter : 800 / 359997]\n",
      "Train loss : 0.22208, Valid loss : 2.55261, Elapsed time : 6853.41327, Present time : 5/27, 16 : 10\n",
      "Current_accuracy : 58.350, current_norm_ED  : 0.77\n",
      "Best accuracy    : 58.350, Best_norm_ED     : 0.77\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅅㅜㄹㅈㅏㄹㅣ                   | ㅅㅜㄹㅈㅏㄹㅣ                   | 0.9506\tTrue\n",
      "ㅂㅏㄴㅈㅏㅇ                    | ㅇㅔㄹㅈㅣ                     | 0.1475\tFalse\n",
      "ㅈㅜㅇㅣㄴ                     | ㅈㅜㅁㅣㄴ                     | 0.5730\tFalse\n",
      "ㅅㅓㄹㄷㅡㄱㅎㅏㄷㅏ                | ㅅㅓㄹㄷㅡㄱㅎㅏㄷㅏ                | 0.4933\tTrue\n",
      "ㅇㅟㅊㅣㅎㅏㄷㅏ                  | ㅇㅣㄴㅊㅓㄴㅎㅏㄷㅏ                | 0.0919\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 1/30000] [iter : 0 / 359997]\n",
      "Train loss : 0.22397, Valid loss : 2.23266, Elapsed time : 7457.41554, Present time : 5/27, 16 : 20\n",
      "Current_accuracy : 64.833, current_norm_ED  : 0.81\n",
      "Best accuracy    : 64.833, Best_norm_ED     : 0.81\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅈㅗㅇ                       | ㄱㅗㅇ                       | 0.2335\tFalse\n",
      "ㅋㅗㅁㅣㄷㅣ                    | ㅋㅗㅁㅣㄷㅣ                    | 0.8944\tTrue\n",
      "ㅅㅏㅇㄱㅘㄴㅇㅓㅄㄷㅏ               | ㅅㅏㄹㅏㅇㅅㅡㄹㅓㅂㄷㅏ              | 0.6395\tFalse\n",
      "ㅍㅕㅇㅅㅐㅇ                    | ㅍㅕㅇㅅㅐㅇ                    | 0.8381\tTrue\n",
      "ㅈㅏㄱㅏㅇㅛㅇ                   | ㅈㅏㄱㅏㅇㅛㅇ                   | 0.9113\tTrue\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 1/30000] [iter : 100 / 359997]\n",
      "Train loss : 0.18228, Valid loss : 2.06182, Elapsed time : 8248.57902, Present time : 5/27, 16 : 34\n",
      "Current_accuracy : 65.686, current_norm_ED  : 0.82\n",
      "Best accuracy    : 65.686, Best_norm_ED     : 0.82\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅇㅠㄱㄱㅜㄴ                    | ㅇㅠㄱㄱㅜㄴ                    | 0.9113\tTrue\n",
      "ㅂㅕㅇㅅㅣㄹ                    | ㅂㅕㅇㅅㅣㄹ                    | 0.9904\tTrue\n",
      "ㄱㅗㅇㅅㅣㄱ                    | ㄱㅗㅇㅅㅣㄱ                    | 0.9751\tTrue\n",
      "ㅂㅕㄹㅁㅕㅇ                    | ㅂㅕㄹㅁㅕㅇ                    | 0.9040\tTrue\n",
      "ㄱㅕㅇㅜ                      | ㄱㅕㅇㅜ                      | 0.9865\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 1/30000] [iter : 200 / 359997]\n",
      "Train loss : 0.18705, Valid loss : 1.98397, Elapsed time : 9043.87913, Present time : 5/27, 16 : 47\n",
      "Current_accuracy : 67.658, current_norm_ED  : 0.83\n",
      "Best accuracy    : 67.658, Best_norm_ED     : 0.83\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅂㅏㅇㅎㅑㅇ                    | ㅎㅏㄴㄱㅐ                     | 0.0408\tFalse\n",
      "ㅇㅜㄹㄹㅣㄷㅏ                   | ㅇㅜㄹㄹㅣㄷㅏ                   | 0.4854\tTrue\n",
      "ㅈㅜㅇㄱㅜㄱ                    | ㅈㅜㅇㄱㅜㄱ                    | 0.9898\tTrue\n",
      "ㅇㅗㄴ                       | ㅇㅛ                        | 0.5264\tFalse\n",
      "ㅂㅔㄴㅊㅣ                     | ㅂㅔㄴㅊㅣ                     | 0.9823\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 1/30000] [iter : 300 / 359997]\n",
      "Train loss : 0.17973, Valid loss : 2.14301, Elapsed time : 9835.69812, Present time : 5/27, 17 : 0\n",
      "Current_accuracy : 64.994, current_norm_ED  : 0.82\n",
      "Best accuracy    : 67.658, Best_norm_ED     : 0.83\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅌㅜㅈㅏ                      | ㅌㅜㅈㅏ                      | 0.6917\tTrue\n",
      "ㅇㅣㄹㅂㅜ                     | ㅇㅣㄹㅂㅜ                     | 0.8126\tTrue\n",
      "ㄷㅗㄹㅗ                      | ㄷㅗㄹㅗ                      | 0.9889\tTrue\n",
      "ㅇㅑㄱㅎㅗㄴㅈㅏ                  | ㅇㅑㄱㅎㅗㄴㅈㅏ                  | 0.8621\tTrue\n",
      "ㅇㅓㄱㅇㅜㄹㅎㅏㄷㅏ                | ㅈㅓㄴㅎㅘㅎㅏㄷㅏ                 | 0.0369\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 1/30000] [iter : 400 / 359997]\n",
      "Train loss : 0.17772, Valid loss : 1.96569, Elapsed time : 10626.07580, Present time : 5/27, 17 : 13\n",
      "Current_accuracy : 66.661, current_norm_ED  : 0.82\n",
      "Best accuracy    : 67.658, Best_norm_ED     : 0.83\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅅㅏㅇㅛㅇ                     | ㅅㅏㅇㅛㅇ                     | 0.9899\tTrue\n",
      "ㅅㅣㄴㅊㅔㅈㅓㄱ                  | ㅅㅣㄴㅊㅔㅈㅓㄱ                  | 0.6470\tTrue\n",
      "ㅈㅜㅅㅣㄱ                     | ㅈㅜㅅㅣㄱ                     | 0.9974\tTrue\n",
      "ㅈㅣㅅㅗㄱㅈㅓㄱ                  | ㅈㅣㅅㅗㄱㅈㅓㄱ                  | 0.9830\tTrue\n",
      "ㅎㅢㄷㅏ                      | ㅎㅢㄷㅏ                      | 0.8356\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 1/30000] [iter : 500 / 359997]\n",
      "Train loss : 0.18479, Valid loss : 1.87992, Elapsed time : 11416.25876, Present time : 5/27, 17 : 26\n",
      "Current_accuracy : 69.283, current_norm_ED  : 0.84\n",
      "Best accuracy    : 69.283, Best_norm_ED     : 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㄱㅣㄹ                       | ㄱㅣㄹ                       | 0.1549\tTrue\n",
      "ㅈㅏㄴㄷㅣㅂㅏㅌ                  | ㅈㅏㄴㄷㅣㅂㅏㅌ                  | 0.5947\tTrue\n",
      "ㅇㅜㄴㄷㅗㅇㅈㅏㅇ                 | ㅇㅜㄴㄷㅗㅇㅈㅏㅇ                 | 0.9886\tTrue\n",
      "ㅈㅜㄱㅗㅂㅏㄷㄷㅏ                 | ㅈㅗㄱㅡㅁㅏㅎㄷㅏ                 | 0.5335\tFalse\n",
      "ㅅㅜㅎㅏㄱ                     | ㅅㅜㅎㅏㄱ                     | 0.9839\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 1/30000] [iter : 600 / 359997]\n",
      "Train loss : 0.18830, Valid loss : 1.75022, Elapsed time : 12206.36300, Present time : 5/27, 17 : 39\n",
      "Current_accuracy : 70.581, current_norm_ED  : 0.85\n",
      "Best accuracy    : 70.581, Best_norm_ED     : 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅇㅗㅃㅏ                      | ㅇㅗㅃㅏ                      | 0.9767\tTrue\n",
      "ㅈㅓㄱㅗㅅ                     | ㅈㅓㄱㅗㅅ                     | 0.9839\tTrue\n",
      "ㅍㅗㄷㅗ                      | ㅍㅗㄷㅗ                      | 0.6788\tTrue\n",
      "ㅂㅣㅇㅜㅅㄷㅏ                   | ㅈㅣㅇㅜㄷㅏ                    | 0.1596\tFalse\n",
      "ㄷㅜㅇㅓ                      | ㄷㅜㅇㅓ                      | 0.9884\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 1/30000] [iter : 700 / 359997]\n",
      "Train loss : 0.17002, Valid loss : 1.71330, Elapsed time : 13000.23848, Present time : 5/27, 17 : 53\n",
      "Current_accuracy : 70.731, current_norm_ED  : 0.85\n",
      "Best accuracy    : 70.731, Best_norm_ED     : 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㄷㅐㅈㅓㅂㅎㅏㄷㅏ                 | ㄷㅏㅈㅓㅇㅎㅏㄷㅏ                 | 0.2224\tFalse\n",
      "ㅂㅕㅇㅇㅏㄹㅣ                   | ㅊㅐㅇㄱㅣㄷㅏ                   | 0.3554\tFalse\n",
      "ㅎㅐㅁㅂㅓㄱㅓ                   | ㅎㅐㅁㅂㅓㄱㅓ                   | 0.9050\tTrue\n",
      "ㅇㅕㄱ                       | ㅇㅣㄹ                       | 0.0356\tFalse\n",
      "ㅈㅓㅇㅁㅏㄹ                    | ㅈㅓㅁㅏㄴ                     | 0.1312\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 1/30000] [iter : 800 / 359997]\n",
      "Train loss : 0.15619, Valid loss : 1.75424, Elapsed time : 13892.05436, Present time : 5/27, 18 : 10\n",
      "Current_accuracy : 70.156, current_norm_ED  : 0.85\n",
      "Best accuracy    : 70.731, Best_norm_ED     : 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅇㅣㄴㅎㅕㅇ                    | ㅇㅣㄴㅎㅕㅇ                    | 0.9795\tTrue\n",
      "ㄷㅡㅇㅈㅏㅇㅎㅏㄷㅏ                | ㄷㅗㅈㅏㄱㅎㅏㄷㅏ                 | 0.0690\tFalse\n",
      "ㅇㅠㅈㅓㄱ                     | ㅇㅡㅁㅈㅓㅇ                    | 0.4590\tFalse\n",
      "ㅂㅗㅈㅏㅇ                     | ㅂㅗㅈㅏㅇ                     | 0.9959\tTrue\n",
      "ㄱㅘㅎㅏㄱ                     | ㄱㅘㅎㅏㄱ                     | 0.9047\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 2/30000] [iter : 0 / 359997]\n",
      "Train loss : 0.15011, Valid loss : 1.60289, Elapsed time : 14642.09399, Present time : 5/27, 18 : 21\n",
      "Current_accuracy : 73.903, current_norm_ED  : 0.87\n",
      "Best accuracy    : 73.903, Best_norm_ED     : 0.87\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㄱㅗㅍㅡㄷㅏ                    | ㄱㅗㅍㅡㄷㅏ                    | 0.7454\tTrue\n",
      "ㄱㅡㄱㅏㄴ                     | ㄱㅡㄱㅏㄴ                     | 0.9955\tTrue\n",
      "ㅌㅗㄹㅗㄴㅎㅚ                   | ㅌㅗㄹㅗㄴㅎㅚ                   | 0.9176\tTrue\n",
      "ㅂㅏㄹㅏㅁㅈㅣㄱㅎㅏㄷㅏ              | ㅂㅏㄹㅏㅁㅈㅣㄱㅎㅏㄷㅏ              | 0.2442\tTrue\n",
      "ㅁㅣㄹㄱㅏㄹㅜ                   | ㅇㅗㄹㄱㅏㅇㅡㄹ                  | 0.1880\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[epoch : 2/30000] [iter : 100 / 359997]\n",
      "Train loss : 0.14434, Valid loss : 1.80119, Elapsed time : 15527.48224, Present time : 5/27, 18 : 35\n",
      "Current_accuracy : 70.269, current_norm_ED  : 0.85\n",
      "Best accuracy    : 73.903, Best_norm_ED     : 0.87\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅅㅣㄱㅇㅛㄱ                    | ㅅㅣㄱㅇㅛㄱ                    | 0.6392\tTrue\n",
      "ㅈㅓㅇㅂㅏㄴㄷㅐ                  | ㅊㅓㅇㅂㅏㄴㅅㅐ                  | 0.3815\tFalse\n",
      "ㅈㅡㅇㄱㅝㄴ                    | ㅈㅡㅇㄱㅝㄴ                    | 0.7532\tTrue\n",
      "ㅈㅔㅎㅏㄴ                     | ㅈㅔㅎㅏㄴ                     | 0.3648\tTrue\n",
      "ㅈㅓㄹㄷㅐㄹㅗ                   | ㅈㅓㄹㄷㅐㄹㅗ                   | 0.9718\tTrue\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch : 2/30000] [iter : 200 / 359997]\n",
      "Train loss : 0.12138, Valid loss : 1.57966, Elapsed time : 16364.08370, Present time : 5/27, 18 : 49\n",
      "Current_accuracy : 73.119, current_norm_ED  : 0.87\n",
      "Best accuracy    : 73.903, Best_norm_ED     : 0.87\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅈㅣㄹㅡㅁㄱㅣㄹ                  | ㅈㅣㄹㅡㅁㄱㅣ                   | 0.2062\tFalse\n",
      "ㄷㅜㄹㅡㄷㅏ                    | ㄷㅜㄹㅡㄷㅏ                    | 0.8746\tTrue\n",
      "ㅈㅐㄷㅏ                      | ㅈㅐㄷㅏ                      | 0.9998\tTrue\n",
      "ㄴㅡㅇㄷㅗㅇㅈㅓㄱ                 | ㄴㅡㅇㄷㅗㅇㅈㅓㄱ                 | 0.9403\tTrue\n",
      "ㄱㅖㅅㅏㄴㅎㅏㄷㅏ                 | ㅅㅣㅁㅅㅣㅁㅎㅏㄷㅏ                | 0.0945\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "os.makedirs(f'./models/{opt.experiment_name}', exist_ok=True)\n",
    "\n",
    "# set seed\n",
    "random.seed(opt.manualSeed)\n",
    "np.random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "torch.cuda.manual_seed(opt.manualSeed)\n",
    "\n",
    "# set GPU\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = True\n",
    "opt.num_gpu = torch.cuda.device_count()\n",
    "\n",
    "if opt.num_gpu > 1:\n",
    "    print('-------- Use multi GPU setting --------')\n",
    "    opt.workers = opt.workers * opt.num_gpu\n",
    "    opt.batch_size = opt.batch_size * opt.num_gpu\n",
    "\n",
    "train(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "converter = AttnLabelConverter(opt.character)\n",
    "opt.num_class = len(converter.character)\n",
    "model = CTN(opt).to(device)\n",
    "model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, length = converter.encode(label, batch_max_length = opt.batch_max_length)\n",
    "img = img.to(device)\n",
    "text = text.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "output = model(img,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "# ext_output = model.Extract(trans_output)\n",
    "# ext_output_ = ext_output.permute(0, 3,1,2).squeeze(3)\n",
    "# seq_output = model.Seq(ext_output_)\n",
    "# pred_output = model.Pred(seq_output, text)\n",
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
