{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import *\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import easydict\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append('./Whatiswrong')\n",
    "sys.path.append('./Scatter')\n",
    "sys.path.append('./RobustScanner')\n",
    "\n",
    "import re\n",
    "import six\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import utils\n",
    "from utils import *\n",
    "import augs\n",
    "import BaseModel\n",
    "import torch.distributed as dist\n",
    "import en_dataset\n",
    "import ko_dataset\n",
    "from albumentations import GaussNoise, IAAAdditiveGaussianNoise, Compose, OneOf\n",
    "from albumentations.pytorch import ToTensor\n",
    "import evaluate\n",
    "\n",
    "# import PositionEnhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'BaseModel' from './RobustScanner/BaseModel.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(BaseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt\n",
    "opt = easydict.EasyDict({\n",
    "    \"experiment_name\" : f'{utils.SaveDir_maker(base_model = \"RobustScanner\", base_model_dir = \"./models\")}',\n",
    "    'saved_model' : '',\n",
    "    \"manualSeed\" : 1111,\n",
    "    \"imgH\" : 125 ,\n",
    "    \"imgW\" :  125,\n",
    "    \"PAD\" : True ,\n",
    "    'batch_size' : 128,\n",
    "    'data_filtering_off' : True,\n",
    "    'workers' : 20,\n",
    "    'rgb' :True,\n",
    "    'sensitive' : True,\n",
    "    'top_char' : ' !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㄲㄸㅃㅆㅉ',\n",
    "    'middle_char' : ' ㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣㅐㅒㅔㅖㅘㅙㅚㅝㅞㅟㅢ',\n",
    "    'bottom_char' : ' ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㄲㄸㅃㅆㅉㄳㄵㄶㄺㄻㄼㄽㄾㄿㅀㅄ',\n",
    "    'batch_max_length' : 25,\n",
    "    'num_fiducial' : 20,\n",
    "    'output_channel' : 512,\n",
    "    'hidden_size' :256,\n",
    "#     'optimizer' : 'adam',\n",
    "    'lr' : 1,\n",
    "    'rho' : 0.95,\n",
    "    'eps' : 1e-8,\n",
    "    'grad_clip' : 5,\n",
    "    'valInterval' : 3000,\n",
    "    'num_epoch' : 100,\n",
    "    'input_channel' : 3,\n",
    "    'FT' : True,\n",
    "    'extract' : 'resnet',\n",
    "#     'extract' : 'efficientnet-b3',\n",
    "    'pred' : ' '\n",
    "    })\n",
    "\n",
    "top_converter = utils.AttnLabelConverter(opt.top_char)\n",
    "middle_converter = utils.AttnLabelConverter(opt.middle_char)\n",
    "bottom_converter = utils.AttnLabelConverter(opt.bottom_char)\n",
    "opt.top_n_cls = len(top_converter.character)\n",
    "opt.mid_n_cls = len(middle_converter.character)\n",
    "opt.bot_n_cls = len(bottom_converter.character)\n",
    "device = torch.device('cuda') #utils.py 안에 device는 따로 세팅해줘야함\n",
    "\n",
    "def ohem_loss( rate, cls_pred, cls_target ):\n",
    "    batch_size = cls_pred.size(0) \n",
    "    ohem_cls_loss = F.cross_entropy(cls_pred, cls_target, reduction='none', ignore_index=-1)\n",
    "\n",
    "    sorted_ohem_loss, idx = torch.sort(ohem_cls_loss, descending=True)\n",
    "    keep_num = min(sorted_ohem_loss.size()[0], int(batch_size*rate) )\n",
    "    if keep_num < sorted_ohem_loss.size()[0]:\n",
    "        keep_idx_cuda = idx[:keep_num]\n",
    "        ohem_cls_loss = ohem_cls_loss[keep_idx_cuda]\n",
    "    cls_loss = ohem_cls_loss.sum() / keep_num\n",
    "    return cls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset', 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./dataset_light', 'wb') as file:\n",
    "#     pickle.dump(data[:1000], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_per_cls = utils.ClassCounter(data, 'top', top_converter)\n",
    "top_per_cls = list(top_per_cls.values())\n",
    "mid_per_cls = utils.ClassCounter(data, 'mid', middle_converter)\n",
    "mid_per_cls = list(mid_per_cls.values())\n",
    "bot_per_cls = utils.ClassCounter(data, 'bot', bottom_converter)\n",
    "bot_per_cls = list(bot_per_cls.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = Compose([\n",
    "                        OneOf([\n",
    "                                  augs.VinylShining(1),\n",
    "                            augs.GridMask(num_grid=(10,20)),\n",
    "                            augs.RandomAugMix(severity=3, width=3)], p =0.7),\n",
    "                            ToTensor()\n",
    "                       ])\n",
    "train_custom = utils.CustomDataset_jamo(data[ : int(len(data) * 0.98)], resize_shape = (opt.imgH, opt.imgW), transformer=transformers)\n",
    "valid_custom = utils.CustomDataset_jamo(data[ int(len(data) * 0.98): ], resize_shape = (opt.imgH, opt.imgW), transformer=ToTensor())\n",
    "\n",
    "data_loader = DataLoader(train_custom, batch_size = opt.batch_size,  num_workers =15, shuffle=True, drop_last=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_custom, batch_size = opt.batch_size,  num_workers=10, shuffle=True,  drop_last=True, pin_memory=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt):\n",
    "    model = BaseModel.model(opt, device)\n",
    "    print('model parameters. height {}, width {}, num of fiducial {}, input channel {}, output channel {}, hidden size {}, \\\n",
    "    batch max length {}'.format(opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel, opt.hidden_size, opt.batch_max_length))\n",
    "    \n",
    "    # weight initialization\n",
    "    for name, param, in model.named_parameters():\n",
    "        if 'localization_fc2' in name:\n",
    "            print(f'Skip {name} as it is already initializaed')\n",
    "            continue\n",
    "        try:\n",
    "            if 'bias' in name:\n",
    "                init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                init.kaiming_normal_(param)\n",
    "                \n",
    "        except Exception as e :\n",
    "            if 'weight' in name:\n",
    "                param.data.fill_(1)\n",
    "            continue\n",
    "            \n",
    "    # load pretrained model\n",
    "    if opt.saved_model != '':\n",
    "        base_path = './models'\n",
    "        print(f'looking for pretrained model from {os.path.join(base_path, opt.saved_model)}')\n",
    "        \n",
    "        try :\n",
    "            model.load_state_dict(torch.load(os.path.join(base_path, opt.saved_model)))\n",
    "            print('loading complete ')    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('coud not find model')\n",
    "            \n",
    "    #data parallel for multi GPU\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "    model.train() \n",
    "     \n",
    "    # loss\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device) #ignore [GO] token = ignore index 0\n",
    "    log_avg = utils.Averager()\n",
    "    \n",
    "    # filter that only require gradient descent\n",
    "    filtered_parameters = []\n",
    "    params_num = []\n",
    "    for p in filter(lambda p : p.requires_grad, model.parameters()):\n",
    "        filtered_parameters.append(p)\n",
    "        params_num.append(np.prod(p.size()))\n",
    "    print('Tranable params : ', sum(params_num))\n",
    "    \n",
    "    # optimizer\n",
    "    \n",
    "    optimizer = optim.Adadelta(filtered_parameters, lr= opt.lr, rho = opt.rho, eps = opt.eps)\n",
    "#     base_opt = torch.optim.Adam(filtered_parameters, lr=0.0001)\n",
    "#     optimizer = SWA(base_opt)\n",
    "#     optimizer = torch.optim.AdamW(filtered_parameters)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', verbose=True, patience = 2, factor= 0.5 )\n",
    "#     optimizer = adabound.AdaBound(filtered_parameters, lr=1e-3, final_lr=0.1)\n",
    "    \n",
    "    # opt log\n",
    "    with open(f'./models/{opt.experiment_name}/opt.txt', 'a') as opt_file:\n",
    "        opt_log = '---------------------Options-----------------\\n'\n",
    "        args = vars(opt)\n",
    "        for k, v in args.items():\n",
    "            opt_log +=f'{str(k)} : {str(v)}\\n'\n",
    "        opt_log +='---------------------------------------------\\n'\n",
    "        opt_file.write(opt_log)\n",
    "        \n",
    "    #start training\n",
    "    start_time = time.time()\n",
    "    best_accuracy = -1\n",
    "    best_norm_ED = -1\n",
    "    swa_count = 0\n",
    "    \n",
    "    for n_epoch, epoch in enumerate(range(opt.num_epoch)):\n",
    "        for n_iter, data_point in enumerate(data_loader):\n",
    "            \n",
    "            image_tensors, top, mid, bot = data_point \n",
    "\n",
    "            image = image_tensors.to(device)\n",
    "            text_top, length_top = top_converter.encode(top, batch_max_length = opt.batch_max_length)\n",
    "            text_mid, length_mid = middle_converter.encode(mid, batch_max_length = opt.batch_max_length)\n",
    "            text_bot, length_bot = bottom_converter.encode(bot, batch_max_length = opt.batch_max_length)\n",
    "            batch_size = image.size(0)\n",
    "          \n",
    "            pred_top, pred_mid, pred_bot = model(image, text_top[:,:-1], text_mid[:,:-1], text_bot[:,:-1])\n",
    "            \n",
    "            cost_top = criterion(pred_top.view(-1, pred_top.shape[-1]), text_top[:, 1:].contiguous().view(-1))\n",
    "            cost_mid = criterion(pred_mid.view(-1, pred_mid.shape[-1]), text_mid[:, 1:].contiguous().view(-1))\n",
    "            cost_bot = criterion(pred_bot.view(-1, pred_bot.shape[-1]), text_bot[:, 1:].contiguous().view(-1))\n",
    "        \n",
    "#             cost_top = utils.reduced_focal_loss(pred_top.view(-1, pred_top.shape[-1]), text_top[:, 1:].contiguous().view(-1), gamma=2, alpha=0.25, threshold=0.5)\n",
    "#             cost_mid = utils.reduced_focal_loss(pred_mid.view(-1, pred_mid.shape[-1]), text_mid[:, 1:].contiguous().view(-1), gamma=2, alpha=0.25, threshold=0.5)\n",
    "#             cost_bot = utils.reduced_focal_loss(pred_bot.view(-1, pred_bot.shape[-1]), text_bot[:, 1:].contiguous().view(-1), gamma=2, alpha=0.25, threshold=0.5)\n",
    "            \n",
    "#             cost_top = utils.CB_loss(text_top[:, 1:].contiguous().view(-1), pred_top.view(-1, pred_top.shape[-1]), top_per_cls, opt.top_n_cls, 'focal', 0.99, 2)\n",
    "#             cost_mid = utils.CB_loss(text_mid[:, 1:].contiguous().view(-1), pred_mid.view(-1, pred_mid.shape[-1]), mid_per_cls, opt.mid_n_cls, 'focal', 0.99, 2)\n",
    "#             cost_bot = utils.CB_loss(text_bot[:, 1:].contiguous().view(-1), pred_bot.view(-1, pred_bot.shape[-1]), bot_per_cls, opt.bot_n_cls, 'focal', 0.99, 2)\n",
    "            cost = cost_top + cost_mid + cost_bot\n",
    "\n",
    "#             print('Cost top : ', cost_top)\n",
    "#             print('Cost mid : ', cost_mid)\n",
    "#             print('Cost bot : ', cost_bot)\n",
    "            loss_avg = utils.Averager()\n",
    "            loss_avg.add(cost)\n",
    "            \n",
    "            model.zero_grad()\n",
    "            cost.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip) #gradient clipping with 5\n",
    "            optimizer.step()\n",
    "            print(loss_avg.val())\n",
    "\n",
    "            #validation\n",
    "            if (n_iter % opt.valInterval == 0) & (n_iter!=0) :\n",
    "                elapsed_time = time.time() - start_time\n",
    "                with open(f'./models/{opt.experiment_name}/log_train.txt', 'a') as log:\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        valid_loss, current_accuracy, current_norm_ED, pred_top_str, pred_mid_str, pred_bot_str, label_top, label_mid, label_bot, infer_time, length_of_data = evaluate.validation_jamo(model, criterion, valid_loader, top_converter, middle_converter, bottom_converter, opt)\n",
    "                    scheduler.step(current_accuracy)\n",
    "                    model.train()\n",
    "\n",
    "                    present_time = time.localtime()\n",
    "                    loss_log = f'[epoch : {n_epoch}/{opt.num_epoch}] [iter : {n_iter*opt.batch_size} / {int(len(data) * 0.95)}]\\n'+\\\n",
    "                    f'Train loss : {loss_avg.val():0.5f}, Valid loss : {valid_loss:0.5f}, Elapsed time : {elapsed_time:0.5f}, Present time : {present_time[1]}/{present_time[2]}, {present_time[3]+9} : {present_time[4]}'\n",
    "                    loss_avg.reset()\n",
    "\n",
    "                    current_model_log = f'{\"Current_accuracy\":17s}: {current_accuracy:0.3f}, {\"current_norm_ED\":17s}: {current_norm_ED:0.2f}'\n",
    "\n",
    "                    #keep the best\n",
    "                    if current_accuracy > best_accuracy:\n",
    "                        best_accuracy = current_accuracy\n",
    "                        torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/best_accuracy_{round(current_accuracy,2)}.pth')\n",
    "\n",
    "                    if current_norm_ED > best_norm_ED:\n",
    "                        best_norm_ED = current_norm_ED\n",
    "                        torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/best_norm_ED.pth')\n",
    "\n",
    "                    best_model_log = f'{\"Best accuracy\":17s}: {best_accuracy:0.3f}, {\"Best_norm_ED\":17s}: {best_norm_ED:0.2f}'\n",
    "                    loss_model_log = f'{loss_log}\\n{current_model_log}\\n{best_model_log}'\n",
    "                    print(loss_model_log)\n",
    "                    log.write(loss_model_log+'\\n')\n",
    "\n",
    "                    dashed_line = '-'*80\n",
    "                    head = f'{\"Ground Truth\":25s} | {\"Prediction\" :25s}| T/F'\n",
    "                    predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
    "\n",
    "                    random_idx  = np.random.choice(range(len(label_top)), size= 5, replace=False)\n",
    "                    label_concat = np.concatenate([np.asarray(label_top).reshape(1,-1), np.asarray(label_mid).reshape(1,-1), np.asarray(label_bot).reshape(1,-1)], axis=0).reshape(3,-1)\n",
    "                    pred_concat = np.concatenate([np.asarray(pred_top_str).reshape(1,-1), np.asarray(pred_mid_str).reshape(1,-1), np.asarray(pred_bot_str).reshape(1,-1)], axis=0).reshape(3,-1)\n",
    "                    \n",
    "                    for i in random_idx:\n",
    "                        label_sample = label_concat[:, i]\n",
    "                        pred_sample = pred_concat[:, i]\n",
    "\n",
    "                        gt_str = utils.str_combine(label_sample[0], label_sample[1], label_sample[2])\n",
    "                        pred_str = utils.str_combine(pred_sample[0], pred_sample[1], pred_sample[2])\n",
    "                        predicted_result_log += f'{gt_str:25s} | {pred_str:25s} | \\t{str(pred_str == gt_str)}\\n'\n",
    "                    predicted_result_log += f'{dashed_line}'\n",
    "                    print(predicted_result_log)\n",
    "                    log.write(predicted_result_log+'\\n')\n",
    "                    \n",
    "                # Stochastic weight averaging\n",
    "#                 optimizer.update_swa()\n",
    "#                 swa_count+=1\n",
    "#                 if swa_count % 3 ==0:\n",
    "#                     optimizer.swap_swa_sgd()\n",
    "#                     torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/swa_{swa_count}.pth')\n",
    "\n",
    "        if (n_epoch) % 5 ==0:\n",
    "            torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/{n_epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2646, device='cuda:0')\n",
      "tensor(4.2933, device='cuda:0')\n",
      "tensor(4.0163, device='cuda:0')\n",
      "tensor(4.5785, device='cuda:0')\n",
      "tensor(4.1237, device='cuda:0')\n",
      "tensor(4.2358, device='cuda:0')\n",
      "tensor(4.2477, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(f'./models/{opt.experiment_name}', exist_ok=True)\n",
    "\n",
    "# set seed\n",
    "random.seed(opt.manualSeed)\n",
    "np.random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "torch.cuda.manual_seed(opt.manualSeed)\n",
    "\n",
    "# set GPU\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = True\n",
    "opt.num_gpu = torch.cuda.device_count()\n",
    "\n",
    "# if opt.num_gpu > 1:\n",
    "#     print('-------- Use multi GPU setting --------')\n",
    "#     opt.workers = opt.workers * opt.num_gpu\n",
    "#     opt.batch_size = opt.batch_size * opt.num_gpu\n",
    "\n",
    "train(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterer = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point  = next(iterer)\n",
    "image, top, mid, bot = point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel.model(opt, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_top, length_top = top_converter.encode(top, batch_max_length = opt.batch_max_length)\n",
    "text_mid, length_mid = middle_converter.encode(mid, batch_max_length = opt.batch_max_length)\n",
    "text_bot, length_bot = bottom_converter.encode(bot, batch_max_length = opt.batch_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
