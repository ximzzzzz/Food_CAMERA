{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import *\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import easydict\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append('./Whatiswrong')\n",
    "sys.path.append('./Scatter')\n",
    "sys.path.append('./RobustScanner')\n",
    "sys.path.append('./Nchar_clf')\n",
    "\n",
    "import re\n",
    "import six\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import utils\n",
    "from utils import *\n",
    "import augs\n",
    "import augs2\n",
    "import BaseModel\n",
    "import torch.distributed as dist\n",
    "import en_dataset\n",
    "import ko_dataset\n",
    "from albumentations import GaussNoise, IAAAdditiveGaussianNoise, Compose, OneOf\n",
    "from albumentations.pytorch import ToTensor\n",
    "import albumentations\n",
    "import evaluate\n",
    "import cv2\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import Nchar_utils\n",
    "import torch.multiprocessing as mp\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]= '2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reload() argument must be a module",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d69fe141fe39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEfficientNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reload() argument must be a module\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__spec__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reload() argument must be a module"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "# importlib.reload(EfficientNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt\n",
    "opt = easydict.EasyDict({\n",
    "    \"experiment_name\" : f'{utils.SaveDir_maker(base_model = \"RobustScanner_nchar\", base_model_dir = \"./models\")}',\n",
    "    'saved_model' : 'RobustScanner_nchar_1106/1/best_accuracy_83.53.pth',\n",
    "#     'saved_model' : '',\n",
    "    \"manualSeed\" : 1111,\n",
    "    \"imgH\" : 64 ,\n",
    "    \"imgW\" :  320, # 64/4 * 20(assume 20 is max seq)\n",
    "    \"PAD\" : True ,\n",
    "    'batch_size' : 128,\n",
    "    'top_char' : ' !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㄲㄸㅃㅆㅉ',\n",
    "    'middle_char' : ' ㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣㅐㅒㅔㅖㅘㅙㅚㅝㅞㅟㅢ',\n",
    "    'bottom_char' : ' ㄱㄴㄷㄹㅁㅂㅅㅇㅈㅊㅋㅌㅍㅎㄲㄸㅃㅆㅉㄳㄵㄶㄺㄻㄼㄽㄾㄿㅀㅄ',\n",
    "    'batch_max_length' : 23,\n",
    "    'num_fiducial' : 20,\n",
    "    'output_channel' : 512,\n",
    "    'hidden_size' : 256,\n",
    "    'num_processes' : 2,\n",
    "    'lr' : 1,\n",
    "    'rho' : 0.95,\n",
    "    'eps' : 1e-8,\n",
    "    'grad_clip' : 5,\n",
    "    'valInterval' : 1500,\n",
    "    'num_epoch' : 10,\n",
    "    'input_channel' : 3,\n",
    "    'FT' : True,\n",
    "    'extract' : 'resnet',\n",
    "#     'extract' : 'efficientnet-b6',\n",
    "    'pred' : ' ',\n",
    "    'nchar_name' : 'efficientnet-b0',\n",
    "    'nchar_pretrained_path' : './Nchar_clf/models',\n",
    "    })\n",
    "device = torch.device('cuda')\n",
    "top_converter = utils.AttnLabelConverter(opt.top_char, device)\n",
    "middle_converter = utils.AttnLabelConverter(opt.middle_char, device)\n",
    "bottom_converter = utils.AttnLabelConverter(opt.bottom_char, device)\n",
    "opt.top_n_cls = len(top_converter.character)\n",
    "opt.mid_n_cls = len(middle_converter.character)\n",
    "opt.bot_n_cls = len(bottom_converter.character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset_180', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "# with open('./dataset_light', 'wb') as file:\n",
    "#     pickle.dump(data[:1000], file)\n",
    "train_data = data[ : int(len(data) * 0.998)]\n",
    "test_data = data[ int(len(data) * 0.998): ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N char Classifier\n",
    "## Nchar dataloader\n",
    "nchar_dataset = Nchar_utils.CustomDataset_clf(train_data, device=device, is_module=True, is_train=False)\n",
    "nchar_dataloader = DataLoader(nchar_dataset, batch_size = opt.batch_size , pin_memory=True, drop_last=True, num_workers = 10)\n",
    "valid_dataset = Nchar_utils.CustomDataset_clf(test_data, device=device, is_module=True, is_train=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = opt.batch_size , pin_memory=True, drop_last=True, num_workers = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nchar_iterer = iter(nchar_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, top, mid, bot = next(nchar_iterer)\n",
    "# plt.imshow(img[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt):\n",
    "    model = BaseModel.model(opt, device)\n",
    "    print('model parameters. height {}, width {}, num of fiducial {}, input channel {}, output channel {}, hidden size {}, \\\n",
    "    batch max length {}'.format(opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel, opt.hidden_size, opt.batch_max_length))\n",
    "    \n",
    "    # weight initialization\n",
    "    for name, param, in model.named_parameters():\n",
    "        if 'localization_fc2' in name:\n",
    "            print(f'Skip {name} as it is already initializaed')\n",
    "            continue\n",
    "        try:\n",
    "            if 'bias' in name:\n",
    "                init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                init.kaiming_normal_(param)\n",
    "                \n",
    "        except Exception as e :\n",
    "            if 'weight' in name:\n",
    "                param.data.fill_(1)\n",
    "            continue\n",
    "            \n",
    "    # load pretrained model\n",
    "    if opt.saved_model != '':\n",
    "        base_path = './models'\n",
    "        print(f'looking for pretrained model from {os.path.join(base_path, opt.saved_model)}')\n",
    "        \n",
    "        try :\n",
    "            model.load_state_dict(torch.load(os.path.join(base_path, opt.saved_model)))\n",
    "            print('loading complete ')    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('coud not find model')\n",
    "            \n",
    "    #data parallel for multi GPU\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0,1,2]).to(device)\n",
    "    model.train() \n",
    "     \n",
    "    # loss\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device) #ignore [GO] token = ignore index 0\n",
    "    log_avg = utils.Averager()\n",
    "    \n",
    "    # filter that only require gradient descent\n",
    "    filtered_parameters = []\n",
    "    params_num = []\n",
    "    for p in filter(lambda p : p.requires_grad, model.parameters()):\n",
    "        filtered_parameters.append(p)\n",
    "        params_num.append(np.prod(p.size()))\n",
    "    print('Tranable params : ', sum(params_num))\n",
    "    \n",
    "    # optimizer\n",
    "    \n",
    "    optimizer = optim.Adadelta(filtered_parameters, lr= opt.lr, rho = opt.rho, eps = opt.eps)\n",
    "#     optimizer = torch.optim.Adam(filtered_parameters, lr=0.0001)\n",
    "#     optimizer = SWA(base_opt)\n",
    "#     optimizer = torch.optim.AdamW(filtered_parameters)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', verbose=True, patience = 2, factor= 0.5 )\n",
    "#     optimizer = adabound.AdaBound(filtered_parameters, lr=1e-3, final_lr=0.1)\n",
    "    \n",
    "    # opt log\n",
    "    with open(f'./models/{opt.experiment_name}/opt.txt', 'a') as opt_file:\n",
    "        opt_log = '---------------------Options-----------------\\n'\n",
    "        args = vars(opt)\n",
    "        for k, v in args.items():\n",
    "            opt_log +=f'{str(k)} : {str(v)}\\n'\n",
    "        opt_log +='---------------------------------------------\\n'\n",
    "        opt_file.write(opt_log)\n",
    "        \n",
    "    #start training\n",
    "    start_time = time.time()\n",
    "    best_accuracy = -1\n",
    "    best_norm_ED = -1\n",
    "    swa_count = 0\n",
    "    \n",
    "    for n_epoch, epoch in enumerate(range(opt.num_epoch)):\n",
    "        for n_iter, data_point in enumerate(nchar_dataloader):\n",
    "            \n",
    "            image_tensors, top, mid, bot = data_point \n",
    "\n",
    "            image = image_tensors.to(device)\n",
    "            text_top, length_top = top_converter.encode(top, batch_max_length = opt.batch_max_length)\n",
    "            text_mid, length_mid = middle_converter.encode(mid, batch_max_length = opt.batch_max_length)\n",
    "            text_bot, length_bot = bottom_converter.encode(bot, batch_max_length = opt.batch_max_length)\n",
    "            batch_size = image.size(0)\n",
    "          \n",
    "            pred_top, pred_mid, pred_bot = model(image, text_top[:,:-1], text_mid[:,:-1], text_bot[:,:-1])\n",
    "            \n",
    "            cost_top = criterion(pred_top.view(-1, pred_top.shape[-1]), text_top[:, 1:].contiguous().view(-1))\n",
    "            cost_mid = criterion(pred_mid.view(-1, pred_mid.shape[-1]), text_mid[:, 1:].contiguous().view(-1))\n",
    "            cost_bot = criterion(pred_bot.view(-1, pred_bot.shape[-1]), text_bot[:, 1:].contiguous().view(-1))\n",
    "        \n",
    "#             cost_top = utils.reduced_focal_loss(pred_top.view(-1, pred_top.shape[-1]), text_top[:, 1:].contiguous().view(-1), gamma=2, alpha=0.25, threshold=0.5)\n",
    "#             cost_mid = utils.reduced_focal_loss(pred_mid.view(-1, pred_mid.shape[-1]), text_mid[:, 1:].contiguous().view(-1), gamma=2, alpha=0.25, threshold=0.5)\n",
    "#             cost_bot = utils.reduced_focal_loss(pred_bot.view(-1, pred_bot.shape[-1]), text_bot[:, 1:].contiguous().view(-1), gamma=2, alpha=0.25, threshold=0.5)\n",
    "            \n",
    "#             cost_top = utils.CB_loss(text_top[:, 1:].contiguous().view(-1), pred_top.view(-1, pred_top.shape[-1]), top_per_cls, opt.top_n_cls, 'focal', 0.99, 2)\n",
    "#             cost_mid = utils.CB_loss(text_mid[:, 1:].contiguous().view(-1), pred_mid.view(-1, pred_mid.shape[-1]), mid_per_cls, opt.mid_n_cls, 'focal', 0.99, 2)\n",
    "#             cost_bot = utils.CB_loss(text_bot[:, 1:].contiguous().view(-1), pred_bot.view(-1, pred_bot.shape[-1]), bot_per_cls, opt.bot_n_cls, 'focal', 0.99, 2)\n",
    "           \n",
    "            cost = cost_top + cost_mid + cost_bot\n",
    "\n",
    "            loss_avg = utils.Averager()\n",
    "            loss_avg.add(cost)\n",
    "            \n",
    "            model.zero_grad()\n",
    "            cost.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip) #gradient clipping with 5\n",
    "            optimizer.step()\n",
    "#             print(loss_avg.val())\n",
    "\n",
    "            #validation\n",
    "            if (n_iter % opt.valInterval == 0) & (n_iter!=0)  :\n",
    "#              & (n_iter!=0)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                with open(f'./models/{opt.experiment_name}/log_train.txt', 'a') as log:\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        valid_loss, current_accuracy, current_norm_ED, pred_top_str, pred_mid_str, pred_bot_str, label_top, label_mid, label_bot, infer_time, length_of_data = evaluate.validation_jamo(model, criterion, valid_loader, top_converter, middle_converter, bottom_converter, opt)\n",
    "                    scheduler.step(current_accuracy)\n",
    "                    model.train()\n",
    "\n",
    "                    present_time = time.localtime()\n",
    "                    loss_log = f'[epoch : {n_epoch}/{opt.num_epoch}] [iter : {n_iter*opt.batch_size} / {int(len(data) * 0.955)}]\\n'+\\\n",
    "                    f'Train loss : {loss_avg.val():0.5f}, Valid loss : {valid_loss:0.5f}, Elapsed time : {elapsed_time:0.5f}, Present time : {present_time[1]}/{present_time[2]}, {present_time[3]+9} : {present_time[4]}'\n",
    "                    loss_avg.reset()\n",
    "\n",
    "                    current_model_log = f'{\"Current_accuracy\":17s}: {current_accuracy:0.3f}, {\"current_norm_ED\":17s}: {current_norm_ED:0.2f}'\n",
    "\n",
    "                    #keep the best\n",
    "                    if current_accuracy > best_accuracy:\n",
    "                        best_accuracy = current_accuracy\n",
    "                        torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/best_accuracy_{round(current_accuracy,2)}.pth')\n",
    "\n",
    "                    if current_norm_ED > best_norm_ED:\n",
    "                        best_norm_ED = current_norm_ED\n",
    "                        torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/best_norm_ED.pth')\n",
    "\n",
    "                    best_model_log = f'{\"Best accuracy\":17s}: {best_accuracy:0.3f}, {\"Best_norm_ED\":17s}: {best_norm_ED:0.2f}'\n",
    "                    loss_model_log = f'{loss_log}\\n{current_model_log}\\n{best_model_log}'\n",
    "                    print(loss_model_log)\n",
    "                    log.write(loss_model_log+'\\n')\n",
    "\n",
    "                    dashed_line = '-'*80\n",
    "                    head = f'{\"Ground Truth\":25s} | {\"Prediction\" :25s}| T/F'\n",
    "                    predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
    "\n",
    "                    random_idx  = np.random.choice(range(len(label_top)), size= 5, replace=False)\n",
    "                    label_concat = np.concatenate([np.asarray(label_top).reshape(1,-1), np.asarray(label_mid).reshape(1,-1), np.asarray(label_bot).reshape(1,-1)], axis=0).reshape(3,-1)\n",
    "                    pred_concat = np.concatenate([np.asarray(pred_top_str).reshape(1,-1), np.asarray(pred_mid_str).reshape(1,-1), np.asarray(pred_bot_str).reshape(1,-1)], axis=0).reshape(3,-1)\n",
    "                    \n",
    "                    for i in random_idx:\n",
    "                        label_sample = label_concat[:, i]\n",
    "                        pred_sample = pred_concat[:, i]\n",
    "\n",
    "                        gt_str = utils.str_combine(label_sample[0], label_sample[1], label_sample[2])\n",
    "                        pred_str = utils.str_combine(pred_sample[0], pred_sample[1], pred_sample[2])\n",
    "                        predicted_result_log += f'{gt_str:25s} | {pred_str:25s} | \\t{str(pred_str == gt_str)}\\n'\n",
    "                    predicted_result_log += f'{dashed_line}'\n",
    "                    print(predicted_result_log)\n",
    "                    log.write(predicted_result_log+'\\n')\n",
    "                    \n",
    "                # Stochastic weight averaging\n",
    "#                 optimizer.update_swa()\n",
    "#                 swa_count+=1\n",
    "#                 if swa_count % 3 ==0:\n",
    "#                     optimizer.swap_swa_sgd()\n",
    "#                     torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/swa_{swa_count}.pth')\n",
    "\n",
    "        if (n_epoch) % 5 ==0:\n",
    "            torch.save(model.module.state_dict(), f'./models/{opt.experiment_name}/{n_epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model parameters. height 64, width 320, num of fiducial 20, input channel 3, output channel 512, hidden size 256,     batch max length 23\n",
      "Skip Trans.LocalizationNetwork.localization_fc2.weight as it is already initializaed\n",
      "Skip Trans.LocalizationNetwork.localization_fc2.bias as it is already initializaed\n",
      "looking for pretrained model from ./models/RobustScanner_nchar_1106/1/best_accuracy_83.53.pth\n",
      "loading complete \n",
      "Tranable params :  55712128\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(f'./models/{opt.experiment_name}', exist_ok=True)\n",
    "\n",
    "# set seed\n",
    "random.seed(opt.manualSeed)\n",
    "np.random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "torch.cuda.manual_seed(opt.manualSeed)\n",
    "\n",
    "# set GPU\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = True\n",
    "opt.num_gpu = torch.cuda.device_count()\n",
    "\n",
    "# if opt.num_gpu > 1:\n",
    "#     print('-------- Use multi GPU setting --------')\n",
    "#     opt.workers = opt.workers * opt.num_gpu\n",
    "#     opt.batch_size = opt.batch_size * opt.num_gpu\n",
    "\n",
    "train(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rank, opt, model, device):\n",
    "#     model, \n",
    "#     torch.manual_seed(opt.manualSeed + rank)\n",
    "    print('이거는됨?')\n",
    "#     train_loader = DataLoader(dataset, **dataloader_kwargs)\n",
    "    \n",
    "#     # filter that only require gradient descent\n",
    "#     filtered_parameters = []\n",
    "#     params_num = []\n",
    "#     for p in filter(lambda p : p.requires_grad, model.parameters()):\n",
    "#         filtered_parameters.append(p)\n",
    "#         params_num.append(np.prod(p.size()))\n",
    "\n",
    "#     # optimizer\n",
    "#     optimizer = optim.Adadelta(filtered_parameters, lr= opt.lr, rho = opt.rho, eps = opt.eps)\n",
    "    \n",
    "#     # loss\n",
    "#     criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device) #ignore [GO] token = ignore index 0\n",
    "#     log_avg = utils.Averager()\n",
    "    \n",
    "#     # label encoder\n",
    "#     top_converter = utils.AttnLabelConverter(opt.top_char, device)\n",
    "#     middle_converter = utils.AttnLabelConverter(opt.middle_char, device)\n",
    "#     bottom_converter = utils.AttnLabelConverter(opt.bottom_char, device)\n",
    "    \n",
    "#     for epoch in range(1, opt.num_epoch + 1):\n",
    "#         model.train()\n",
    "#         pid = os.getpid()\n",
    "#         for idx, (image_tensors, top, mid, bot) in enumerate(train_loader):\n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             image = image_tensors.to(device)\n",
    "#             text_top, length_top = top_converter.encode(top, batch_max_length = opt.batch_max_length)\n",
    "#             text_mid, length_mid = middle_converter.encode(mid, batch_max_length = opt.batch_max_length)\n",
    "#             text_bot, length_bot = bottom_converter.encode(bot, batch_max_length = opt.batch_max_length)\n",
    "#             batch_size = image.size(0)\n",
    "          \n",
    "#             pred_top, pred_mid, pred_bot = model(image, text_top[:,:-1], text_mid[:,:-1], text_bot[:,:-1])\n",
    "            \n",
    "#             cost_top = criterion(pred_top.view(-1, pred_top.shape[-1]), text_top[:, 1:].contiguous().view(-1))\n",
    "#             cost_mid = criterion(pred_mid.view(-1, pred_mid.shape[-1]), text_mid[:, 1:].contiguous().view(-1))\n",
    "#             cost_bot = criterion(pred_bot.view(-1, pred_bot.shape[-1]), text_bot[:, 1:].contiguous().view(-1))\n",
    "            \n",
    "#             cost = cost_top + cost_mid + cost_bot\n",
    "\n",
    "#             loss_avg = utils.Averager()\n",
    "#             loss_avg.add(cost)\n",
    "            \n",
    "#             model.zero_grad()\n",
    "#             cost.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip) #gradient clipping with 5\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             if batch_idx % 5 == 0:\n",
    "#                 print('{}\\tTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 pid, epoch, idx * len(image_tensors), len(data_loader.dataset),\n",
    "#                 100. * idx / len(data_loader), loss_avg.val()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(opt, model, device, dataset, dataloader_kwargs):\n",
    "#     torch.manual_seed(opt.manualSeed)\n",
    "#     test_loader = DataLoader(dataset, **dataloader_kwargs)\n",
    "    \n",
    "#     model.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./dataset_180', 'rb') as file:\n",
    "#     data = pickle.load(file)\n",
    "\n",
    "# train_data = data[ : int(len(data) * 0.998)]\n",
    "# test_data = data[ int(len(data) * 0.998): ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_length = len(train_data)// opt.num_processes\n",
    "train_split = []\n",
    "for prc_idx in range(opt.num_processes):\n",
    "    splited_data = train_data[prc_idx * each_length : (prc_idx+1) * each_length]\n",
    "    train_split.append(splited_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(opt.manualSeed)\n",
    "dataloader_kwargs = {'batch_size' : opt.batch_size, 'pin_memory' : True, 'drop_last':True, 'num_workers' : 1}\n",
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for pretrained model from ./models/RobustScanner_1105/1/best_accuracy_69.23.pth\n",
      "loading complete \n"
     ]
    }
   ],
   "source": [
    "model = BaseModel.model(opt, device)\n",
    "# load pretrained model\n",
    "if opt.saved_model != '':\n",
    "    base_path = './models'\n",
    "    print(f'looking for pretrained model from {os.path.join(base_path, opt.saved_model)}')\n",
    "\n",
    "    try :\n",
    "        model.load_state_dict(torch.load(os.path.join(base_path, opt.saved_model)))\n",
    "        print('loading complete ')    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('coud not find model')\n",
    "\n",
    "#data parallel for multi GPU\n",
    "# model = torch.nn.DataParallel(model, device_ids=[0,1,2,3]).to(device)\n",
    "model = model.to(device)\n",
    "_ = model.share_memory() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e01b5d8670d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# model,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     p = mp.Process(target= train2, )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprocesses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparent_r\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "processes = []\n",
    "for rank in range(opt.num_processes):\n",
    "#     dataset = train_split[rank]\n",
    "    p = mp.Process(target= train, args = ( rank, opt, model , device ) ) # model, \n",
    "#     p = mp.Process(target= train2, )\n",
    "    p.start()\n",
    "    print('start!')\n",
    "    processes.append(p)\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
