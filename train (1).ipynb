{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import PIL as pil\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import easydict\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import six\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils import AttnLabelConverter, Averager, AlignCollate\n",
    "import utils\n",
    "from Trans import TPS_SpatialTransformerNetwork\n",
    "import Trans\n",
    "from Extract import RCNN_extractor\n",
    "from Extract import EfficientNet\n",
    "import Extract\n",
    "from Seq import BidirectionalLSTM\n",
    "import Seq\n",
    "from Pred import Attention\n",
    "import Pred\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import *\n",
    "from jamo import h2j, j2hcj\n",
    "import gc\n",
    "\n",
    "def json_loader(path):\n",
    "    with open(path, 'r') as json_file:\n",
    "        file = json.load(json_file)\n",
    "    return file\n",
    "\n",
    "def img_annot_split(label):\n",
    "    label_images = pd.DataFrame(label['images'])\n",
    "    label_annot = pd.DataFrame(label['annotations'])\n",
    "    return label_images, label_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Trans' from '/Data/FoodDetection/AI_OCR/Trans.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(Trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arguements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt\n",
    "opt = easydict.EasyDict({\n",
    "    \"experiment_name\" : 'first_0520',\n",
    "    \"manualSeed\" : 1111,\n",
    "    \"imgH\" : 35 ,\n",
    "    \"imgW\" :  90,\n",
    "    \"PAD\" : True ,\n",
    "    'batch_size' : 256,\n",
    "    'data_filtering_off' : True,\n",
    "    'workers' : 20,\n",
    "    'rgb' :True,\n",
    "    'sensitive' : True,\n",
    "    'character' : '0123456789ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎㄵㄶㄺㄻㅀㄼㅄㅏㅑㅓㅕㅗㅛㅜㅠㅡㅣㅐㅒㅔㅖㅢㅟㅝㅞㅚㅘㅙ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~' ,\n",
    "    'batch_max_length' : 25,\n",
    "    'num_fiducial' : 20,\n",
    "    'output_channel' : 512,\n",
    "    'hidden_size' :256,\n",
    "    'lr' : 1,\n",
    "    'rho' : 0.95,\n",
    "    'eps' : 1e-8,\n",
    "    'grad_clip' : 5,\n",
    "    'valInterval' : 20,\n",
    "    'num_iter' : 3000,\n",
    "    'input_channel' : 3\n",
    "    })\n",
    "\n",
    "device = torch.device('cuda:1') #utils.py 안에 device는 따로 세팅해줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eff = EfficientNet()\n",
    "# trans_output = torch.FloatTensor(10, 3, opt.imgH, opt.imgH)\n",
    "# feature_output = eff(trans_output)\n",
    "# feature_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359997/359997 [00:20<00:00, 17461.06it/s]\n"
     ]
    }
   ],
   "source": [
    "base_path = '/Data/KoreanSTR/'\n",
    "\n",
    "# path_wild = '/Data/KoreanSTR/textinthewild_data_info.json'\n",
    "# path_printed = '/Data/KoreanSTR/printed_data_info.json'\n",
    "path_hand = '/Data/KoreanSTR/handwriting_data_info1.json'\n",
    "# path_aug = '/Data/KoreanSTR/augmentation_data_info.json'\n",
    "\n",
    "label_hand = json_loader(path_hand)\n",
    "label_hand_images, label_hand_annot = img_annot_split(label_hand)\n",
    "\n",
    "label_hand_annot = label_hand_annot[['id','text']]\n",
    "\n",
    "dataset = '1_word'\n",
    "file_list_word = os.listdir(os.path.join(base_path, dataset))\n",
    "files_word = pd.DataFrame(file_list_word, columns=['file_name'])\n",
    "files_word['id'] = files_word['file_name'].apply(lambda x : x.replace('.png',''))\n",
    "files_labels = pd.merge(files_word, label_hand_annot, how='left', left_on='id',right_on='id' )\n",
    "\n",
    "word_data = []\n",
    "random_idx = np.random.choice(range(len(files_labels)), size= int(len(files_labels) * 1), replace=False)\n",
    "for file in tqdm(files_labels.loc[random_idx]['file_name']):\n",
    "#     img_arr = np.asarray(Image.open(os.path.join(base_path, dataset, file)))\n",
    "    img_arr = Image.open(os.path.join(base_path, dataset, file))\n",
    "    word_data.append(img_arr)\n",
    "    \n",
    "labels = [j2hcj(h2j(x)) for x in files_labels['text']]\n",
    "\n",
    "Dataset = []\n",
    "for img, text in zip(word_data, labels):\n",
    "    Dataset.append((img, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 294, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=294x194 at 0x7FE514589668>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 3000\n",
    "print(np.array(Dataset[idx][0]).shape)\n",
    "Dataset[idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_AlignCollate = utils.AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=True)\n",
    "data_loader = DataLoader(Dataset[:int(len(Dataset)*0.9)], batch_size = opt.batch_size, shuffle=True, num_workers = 0, \n",
    "                         collate_fn = _AlignCollate,pin_memory=False )\n",
    "data_loader_iter = iter(data_loader)\n",
    "\n",
    "#for valid\n",
    "_AlignCollate_valid = utils.AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=True)\n",
    "valid_loader = DataLoader(Dataset[int(len(Dataset)*0.9) : ], batch_size = opt.batch_size, shuffle =True, num_workers=0, \n",
    "                          collate_fn=_AlignCollate_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = data_loader_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 150, 450])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTN(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(CTN, self).__init__()\n",
    "        self.opt = opt\n",
    "        \n",
    "        #Trans\n",
    "        self.Trans = Trans.TPS_SpatialTransformerNetwork(F = opt.num_fiducial,\n",
    "                                                  i_size = (opt.imgH, opt.imgW), \n",
    "                                                  i_r_size= (opt.imgH, opt.imgW), \n",
    "                                                  i_channel_num=opt.input_channel,\n",
    "                                                        device = device)\n",
    "        #Extract\n",
    "#         self.Extract = Extract.RCNN_extractor(opt.input_channel, opt.output_channel)\n",
    "#         self.FeatureExtraction_output = opt.output_channel # (imgH/16 -1 )* 512\n",
    "        self.AdaptiveAvgPool = nn.AdaptiveAvgPool2d((None,1)) # imgH/16-1   ->  1\n",
    "        self.Extract = EfficientNet()\n",
    "        \n",
    "        \n",
    "         \n",
    "        # Sequence\n",
    "        self.Seq = nn.Sequential(\n",
    "#             BidirectionalLSTM(self.FeatureExtraction_output, opt.hidden_size,  opt.hidden_size),\n",
    "            BidirectionalLSTM(1536, opt.hidden_size,  opt.hidden_size),\n",
    "            BidirectionalLSTM(opt.hidden_size, opt.hidden_size, opt.hidden_size))\n",
    "        self.Seq_output = opt.hidden_size\n",
    "        \n",
    "        #Pred\n",
    "        self.Pred = Pred.Attention(self.Seq_output, opt.hidden_size, opt.num_class, device=device)\n",
    "        \n",
    "        \n",
    "    def forward(self, input, text, is_train=True):\n",
    "        #Trans stage\n",
    "        input = self.Trans(input)\n",
    "        \n",
    "        #Extract stage\n",
    "        visual_feature = self.Extract(input)\n",
    "        visual_feature = self.AdaptiveAvgPool(visual_feature.permute(0, 3, 1, 2))\n",
    "        visual_feature = visual_feature.squeeze(3)\n",
    "        \n",
    "        #Seq stage\n",
    "        contextual_feature = self.Seq(visual_feature)\n",
    "        #Pred stage\n",
    "        prediction = self.Pred(contextual_feature.contiguous(), text, is_train, batch_max_length = self.opt.batch_max_length)\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt):\n",
    "    converter = AttnLabelConverter(opt.character)\n",
    "    opt.num_class = len(converter.character)\n",
    "    \n",
    "    model = CTN(opt)\n",
    "    print('model parameters. height {}, width {}, num of fiducial {}, input channel {}, output channel {}, hidden size {}, num class {},\\\n",
    "    batch max length {}'.format(opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel, opt.hidden_size, opt.num_class,\n",
    "                               opt.batch_max_length))\n",
    "    \n",
    "    # weight initialization\n",
    "    for name, param, in model.named_parameters():\n",
    "        if 'localization_fc2' in name:\n",
    "            print(f'Skip {name} as it is already initializaed')\n",
    "            continue\n",
    "        try:\n",
    "            if 'bias' in name:\n",
    "                init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                init.kaiming_normal_(param)\n",
    "                \n",
    "        except Exception as e :\n",
    "            if 'weight' in name:\n",
    "                param.data.fill_(1)\n",
    "            continue\n",
    "            \n",
    "    #data parallel for multi GPU\n",
    "#     model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # loss\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device) #ignore [GO] token = ignore index 0\n",
    "    log_avg = Averager()\n",
    "    \n",
    "    # filter that only require gradient descent\n",
    "    filtered_parameters = []\n",
    "    params_num = []\n",
    "    for p in filter(lambda p : p.requires_grad, model.parameters()):\n",
    "        filtered_parameters.append(p)\n",
    "        params_num.append(np.prod(p.size()))\n",
    "    print('Tranable params : ', sum(params_num))\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = optim.Adadelta(filtered_parameters, lr= opt.lr, rho = opt.rho, eps = opt.eps)\n",
    "    \n",
    "    # opt log\n",
    "    with open(f'./models/{opt.experiment_name}/opt.txt', 'a') as opt_file:\n",
    "        opt_log = '---------------------Options-----------------\\n'\n",
    "        args = vars(opt)\n",
    "        for k, v in args.items():\n",
    "            opt_log +=f'{str(k)} : {str(v)}\\n'\n",
    "        opt_log +='---------------------------------------------\\n'\n",
    "        opt_file.write(opt_log)\n",
    "        \n",
    "    #start training\n",
    "    start_iter = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    best_accuracy = -1\n",
    "    best_norm_ED = -1\n",
    "    i = start_iter\n",
    "    \n",
    "    while(True):\n",
    "        image_tensors, labels = data_loader_iter.next()\n",
    "        image = image_tensors.to(device)\n",
    "        text, length = converter.encode(labels, batch_max_length = opt.batch_max_length)\n",
    "\n",
    "        batch_size = image.size(0)\n",
    "        \n",
    "\n",
    "        preds = model(image, text[:, : -1])\n",
    "        target = text[:, 1:]\n",
    "\n",
    "        cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "        \n",
    "        loss_avg = Averager()\n",
    "        \n",
    "        model.zero_grad()\n",
    "        cost.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip) #gradient clipping with 5\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_avg.add(cost)\n",
    "\n",
    "        #validation\n",
    "        if i % opt.valInterval == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            with open(f'./models/{opt.experiment_name}/log_train.txt', 'a') as log:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    valid_loss, current_accuracy, current_norm_ED, preds, confidence_score, labels, infer_time, length_of_data = utils.validation(\n",
    "                        model, criterion, valid_loader, converter, opt)\n",
    "\n",
    "                model.train()\n",
    "                present_time = time.localtime()\n",
    "                loss_log = f'[{i}/{opt.num_iter}] Train loss : {loss_avg.val():0.5f}, Valid loss : {valid_loss:0.5f}, Elapsed time : {elapsed_time:0.5f}, \\\n",
    "                Present time : {present_time[1]}/{present_time[2]}, {present_time[3]+9} : {present_time[4]}'\n",
    "                loss_avg.reset()\n",
    "\n",
    "\n",
    "                current_model_log = f'{\"Current_accuracy\":17s}: {current_accuracy:0.3f}, {\"current_norm_ED\":17s}: {current_norm_ED:0.2f}'\n",
    "\n",
    "\n",
    "                #keep the best\n",
    "                if current_accuracy > best_accuracy:\n",
    "                    best_accuracy = current_accuracy\n",
    "                    torch.save(model.state_dict(), f'./models/{opt.experiment_name}/best_accuracy.pth')\n",
    "\n",
    "                if current_norm_ED > best_norm_ED:\n",
    "                    best_norm_ED = current_norm_ED\n",
    "                    torch.save(model.state_dict(), f'./models/{opt.experiment_name}/best_norm_ED.pth')\n",
    "\n",
    "                best_model_log = f'{\"Best accuracy\":17s}: {best_accuracy:0.3f}, {\"Best_norm_ED\":17s}: {best_norm_ED:0.2f}'\n",
    "                loss_model_log = f'{loss_log}\\n{current_model_log}\\n{best_model_log}'\n",
    "                print(loss_model_log)\n",
    "                log.write(loss_model_log+'\\n')\n",
    "\n",
    "\n",
    "                dashed_line = '-'*80\n",
    "                head = f'{\"Ground Truth\":25s} | {\"Prediction\" :25s}| Confidence Score & T/F'\n",
    "                predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
    "\n",
    "                for gt, pred, confidence in zip(labels[:5], preds[:5], confidence_score[:5]):\n",
    "#                     if 'Attn' in opt.Prediction:\n",
    "                    gt = gt[: gt.find('[s]')]\n",
    "                    pred = pred[: pred.find('[s]')]\n",
    "\n",
    "                    predicted_result_log += f'{gt:25s} | {pred:25s} | {confidence:0.4f}\\t{str(pred == gt)}\\n'\n",
    "                predicted_result_log += f'{dashed_line}'\n",
    "                print(predicted_result_log)\n",
    "                log.write(predicted_result_log+'\\n')\n",
    "\n",
    "\n",
    "        if (i+1)% 1e+5 ==0:\n",
    "            torch.save(model.state_dict(), f'./models/{opt.experiment_name}/iter_{i+1}.pth')\n",
    "\n",
    "\n",
    "        if i==opt.num_iter:\n",
    "            print('end of training')\n",
    "\n",
    "        i +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Use multi GPU setting --------\n",
      "model parameters. height 35, width 90, num of fiducial 20, input channel 3, output channel 512, hidden size 256, num class 91,    batch max length 25\n",
      "Skip Trans.LocalizationNetwork.localization_fc2.weight as it is already initializaed\n",
      "Skip Trans.LocalizationNetwork.localization_fc2.bias as it is already initializaed\n",
      "Tranable params :  18293574\n",
      "[0/3000] Train loss : 4.49904, Valid loss : 4.50357, Elapsed time : 2.66336,                 Present time : 5/21, 18 : 6\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.01\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.01\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅋㅣㄹㄹㅗㄱㅡㄹㅐㅁ                | \\\\++++ㅊ??ㅊ?<ㅈ8ㄺ=ㄶ/ㅉ171ㅒ+ㅊ | 0.0000\tFalse\n",
      "ㅈㅜㅁㅜㄴ                     | \\\\++++ㅊ??ㅊ?<ㅈ8ㄺ=ㄶ/ㅉ171ㅒ+ㅊ | 0.0000\tFalse\n",
      "ㅈㅏㅈㅓㄴㄱㅓ                   | \\\\++++ㅊ??ㅊ?<ㅈ8ㄺ=ㄶ/ㅉ171ㅒ+ㅊ | 0.0000\tFalse\n",
      "ㄱㅕㅇㄱㅖ                     | \\\\++++ㅊ??ㅊ?<ㅈ8ㄺ=ㄶ/ㅉ171ㅒ+ㅊ | 0.0000\tFalse\n",
      "ㄷㅡㄹㄹㅣㄷㅏ                   | \\\\++++ㅊ??ㅊ?<ㅈ8ㄺ=ㄶ/ㅉ171ㅒ+ㅊ | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[20/3000] Train loss : 4.45507, Valid loss : 4.47348, Elapsed time : 176.63600,                 Present time : 5/21, 18 : 8\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.08\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅇㅗㄹㄹㅏㄱㅏㄷㅏ                 | \\ㄴ{ㅏㅏㅏㅏㅏ^                 | 0.0000\tFalse\n",
      "ㅇㅓㄴㄷㅓㄱ                    | \\ㄴ{ㅏㅏㅏㅏㅏ^                 | 0.0000\tFalse\n",
      "ㅈㅔㅇㅏㄴㅎㅏㄷㅏ                 | \\ㄴ{ㅏㅏㅏㅏㅏ^                 | 0.0000\tFalse\n",
      "ㅅㅏㅌㅏㅇ                     | \\ㄴ{ㅏㅏㅏㅏㅏ^                 | 0.0000\tFalse\n",
      "ㄱㅓㄴㅅㅓㄹㅎㅏㄷㅏ                | \\ㄴ{ㅏㅏㅏㅏㅏ^                 | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[40/3000] Train loss : 4.42985, Valid loss : 4.46546, Elapsed time : 289.48840,                 Present time : 5/21, 18 : 9\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.00\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅇㅓㄷㅜㅁ                     | \\                         | 0.0117\tFalse\n",
      "ㄴㅗㄱㅎㅘ                     | \\                         | 0.0117\tFalse\n",
      "ㄱㅜㄴㅅㅏ                     | \\                         | 0.0117\tFalse\n",
      "ㅅㅗㅇㅠ                      | \\                         | 0.0117\tFalse\n",
      "ㅊㅐ                        | \\                         | 0.0117\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[60/3000] Train loss : 4.38301, Valid loss : 4.43488, Elapsed time : 401.52438,                 Present time : 5/21, 18 : 12\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.00\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅈㅣㅂㅐㅎㅏㄷㅏ                  |                           | 0.0000\tFalse\n",
      "ㄱㅘㅇㄱㅕㅇ                    |                           | 0.0000\tFalse\n",
      "ㅈㅏㄹㄹㅣㄷㅏ                   |                           | 0.0000\tFalse\n",
      "ㅇㅖㅅㅣㄱㅈㅏㅇ                  |                           | 0.0000\tFalse\n",
      "ㄱㅡㅇㅑㅁㅏㄹㄹㅗ                 |                           | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[80/3000] Train loss : 4.36934, Valid loss : 4.41083, Elapsed time : 551.35910,                 Present time : 5/21, 18 : 14\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.00\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅂㅐ                        |                           | 0.0000\tFalse\n",
      "ㅇㅓㄹㅣㄴㅇㅏㅇㅣ                 |                           | 0.0000\tFalse\n",
      "ㅊㅏㅅㅈㅏㄴ                    |                           | 0.0000\tFalse\n",
      "ㅈㅓㄴㅎㅘ                     |                           | 0.0000\tFalse\n",
      "ㅊㅗㅂㅏㄴ                     |                           | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[100/3000] Train loss : 4.35033, Valid loss : 4.38934, Elapsed time : 700.74841,                 Present time : 5/21, 18 : 17\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.00\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅌㅓㄱ                       |                           | 0.0000\tFalse\n",
      "ㅎㅕㄴㄷㅐㅈㅓㄱ                  |                           | 0.0000\tFalse\n",
      "ㅂㅣ                        |                           | 0.0000\tFalse\n",
      "ㅅㅏㄴㅇㅓㅂ                    |                           | 0.0000\tFalse\n",
      "ㅂㅜㄹㅎㅐㅇ                    |                           | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[120/3000] Train loss : 4.32030, Valid loss : 4.35870, Elapsed time : 850.07863,                 Present time : 5/21, 18 : 19\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.00\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅈㅣㅂㅐㅎㅏㄷㅏ                  |                           | 0.0000\tFalse\n",
      "ㄷㅜㄴㅚ                      |                           | 0.0000\tFalse\n",
      "ㅊㅣㅁㄷㅐ                     |                           | 0.0000\tFalse\n",
      "ㅅㅣㅈㅣㅂ                     |                           | 0.0000\tFalse\n",
      "ㄱㅗㅇㅈㅜ                     |                           | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[140/3000] Train loss : 4.27645, Valid loss : 4.33140, Elapsed time : 999.67000,                 Present time : 5/21, 18 : 22\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.00\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅈㅗㄴㅈㅜㅇㅎㅏㄷㅏ                |                           | 0.0000\tFalse\n",
      "ㅇㅣㅅㄸㅏㄹㅡㄷㅏ                 |                           | 0.0000\tFalse\n",
      "ㄱㅡㅇㅑㅁㅏㄹㄹㅗ                 |                           | 0.0000\tFalse\n",
      "ㄲㅡㄶㅇㅓㅈㅣㄷㅏ                 |                           | 0.0000\tFalse\n",
      "ㅅㅏㄴㅂㅜㅇㅣㄴㄱㅘ                |                           | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[160/3000] Train loss : 4.26988, Valid loss : 4.30017, Elapsed time : 1149.52106,                 Present time : 5/21, 18 : 24\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.00\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅈㅜㅁㅏㄹ                     |                           | 0.0000\tFalse\n",
      "ㅊㅜㄱㅎㅏ                     |                           | 0.0000\tFalse\n",
      "ㄱㅠㅁㅗ                      |                           | 0.0000\tFalse\n",
      "ㅅㅓㅂㅣㅅㅡ                    |                           | 0.0000\tFalse\n",
      "ㅅㅣㄴㄱㅗ                     |                           | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180/3000] Train loss : 4.21548, Valid loss : 4.24809, Elapsed time : 1299.55713,                 Present time : 5/21, 18 : 27\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.00\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅅㅜㅋㅓㅅ                     |                           | 0.0000\tFalse\n",
      "ㅈㅏㅇㅇㅐㅇㅣㄴ                  |                           | 0.0000\tFalse\n",
      "ㅍㅜㅁㄷㅏ                     |                           | 0.0000\tFalse\n",
      "ㅈㅜㅇㅇㅛㅎㅏㄷㅏ                 |                           | 0.0000\tFalse\n",
      "ㅇㅛㅇㅅㅓㅎㅏㄷㅏ                 |                           | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[200/3000] Train loss : 4.17933, Valid loss : 4.21072, Elapsed time : 1449.74043,                 Present time : 5/21, 18 : 29\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.00\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㄷㅗㄱㄱㅏㅁ                    |                           | 0.0000\tFalse\n",
      "ㅇㅜㄹㅕ                      |                           | 0.0000\tFalse\n",
      "ㄷㅏㄴㅅㅜㄴㅎㅣ                  |                           | 0.0000\tFalse\n",
      "ㄱㅣㄱㅖ                      |                           | 0.0000\tFalse\n",
      "ㄱㅓㄷㅡㅂ                     |                           | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[220/3000] Train loss : 4.12803, Valid loss : 4.17492, Elapsed time : 1600.04297,                 Present time : 5/21, 18 : 32\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.00\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅇㅣㄹㅐ                      |                           | 0.0000\tFalse\n",
      "ㅁㅗㄹㅡㄷㅏ                    |                           | 0.0000\tFalse\n",
      "ㅅㅣㄹㅈㅔㄹㅗ                   |                           | 0.0000\tFalse\n",
      "ㅅㅜㅅㅏㅇ                     |                           | 0.0000\tFalse\n",
      "ㄸㅡㅅㅂㅏㄲㅇㅔ                  |                           | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "[240/3000] Train loss : 4.08055, Valid loss : 4.11242, Elapsed time : 1750.49982,                 Present time : 5/21, 18 : 34\n",
      "Current_accuracy : 0.000, current_norm_ED  : 0.00\n",
      "Best accuracy    : 0.000, Best_norm_ED     : 0.08\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction               | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ㅂㅏㅇㅁㅜㄴㅎㅏㄷㅏ                |                           | 0.0000\tFalse\n",
      "ㅌㅓㄸㅡㄹㅣㄷㅏ                  |                           | 0.0000\tFalse\n",
      "ㅈㅓㅁㅅㅣㅁ                    |                           | 0.0000\tFalse\n",
      "ㄴㅐㅁㅣㄹㄷㅏ                   |                           | 0.0000\tFalse\n",
      "ㅅㅓㅋㅡㄹ                     |                           | 0.0000\tFalse\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(f'./models/{opt.experiment_name}', exist_ok=True)\n",
    "\n",
    "# set seed\n",
    "random.seed(opt.manualSeed)\n",
    "np.random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "torch.cuda.manual_seed(opt.manualSeed)\n",
    "\n",
    "# set GPU\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = True\n",
    "opt.num_gpu = torch.cuda.device_count()\n",
    "\n",
    "if opt.num_gpu > 1:\n",
    "    print('-------- Use multi GPU setting --------')\n",
    "    opt.workers = opt.workers * opt.num_gpu\n",
    "    opt.batch_size = opt.batch_size * opt.num_gpu\n",
    "    \n",
    "train(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = AttnLabelConverter(opt.character)\n",
    "image = img.to(device)\n",
    "text, length = converter.encode(label, batch_max_length = opt.batch_max_length)\n",
    "batch_size = image.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(image, text[:, : -1])\n",
    "target = text[:, 1:]\n",
    "# cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = AttnLabelConverter(opt.character)\n",
    "opt.num_class = len(converter.character)\n",
    "model = CTN(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.FloatTensor(1, 3, opt.imgH, opt.imgW).fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-54f3d19ad89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/FoodDetection/AI_OCR/Trans.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_i)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mbatch_C_prime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocalizationNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size x K x2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mbuild_P_prime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridGenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_P_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_C_prime\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size x n x 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mbuild_P_prime_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_P_prime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuild_P_prime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi_r_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi_r_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/FoodDetection/AI_OCR/Trans.py\u001b[0m in \u001b[0;36mbuild_P_prime\u001b[0;34m(self, batch_C_prime)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mbatch_inv_delta_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_delta_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mbatch_P_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mbatch_C_prime_with_zeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_C_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0;31m# batch_size x F+3 x 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mbatch_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inv_delta_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_C_prime_with_zeros\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size x F+3 x 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "test_output = model.Trans(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 3, 35, 90])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "extract_output = model.Extract(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 512, 1, 23])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_feature = torch.FloatTensor(10, 512, 1, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_feature_ = visual_feature.permute(0, 3, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.9792e-40,  1.7541e+19,  5.1695e+07,  ...,  5.6938e-39,\n",
       "           1.7279e-41,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.8754e+28,  2.7347e+20,  ...,  1.4372e-41,\n",
       "           3.5816e-39,  1.9411e-41],\n",
       "         [ 6.4304e-39,  6.9146e+28,  1.6244e+19,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  5.9693e-39],\n",
       "         ...,\n",
       "         [ 6.6814e-07,  1.6244e+19,  6.8589e+22,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  5.9694e-39],\n",
       "         [ 1.9209e+31,  1.7443e+28,  1.5435e+25,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  1.5829e-41],\n",
       "         [ 4.8403e+30,  3.5561e-09,  5.1694e+07,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 2.6457e-42,  0.0000e+00,  0.0000e+00,  ...,  1.5246e-42,\n",
       "           9.0678e-42,  1.4586e-39],\n",
       "         [ 0.0000e+00,  5.1568e-43,  0.0000e+00,  ...,  7.5232e-37,\n",
       "           1.3677e-42, -2.2656e+38],\n",
       "         [ 2.1204e-41,  0.0000e+00,  0.0000e+00,  ...,  1.4586e-39,\n",
       "           7.5232e-37,  3.5733e-43],\n",
       "         ...,\n",
       "         [ 2.2248e-41,  0.0000e+00,  0.0000e+00,  ...,  5.6052e-45,\n",
       "           4.3087e-41,  1.4550e-39],\n",
       "         [ 6.0612e-39,  2.4244e-41,  0.0000e+00,  ...,  2.1367e-34,\n",
       "           0.0000e+00,  7.2205e-41],\n",
       "         [ 1.4417e-41,  8.3570e-39,  2.6846e-41,  ...,  1.4586e-39,\n",
       "           1.4161e-36,  4.9326e-43]],\n",
       "\n",
       "        [[ 7.5232e-37,  0.0000e+00,  1.8253e-12,  ...,  6.2778e-43,\n",
       "           4.3278e-31,  4.2825e-39],\n",
       "         [ 1.4615e-39,  8.6096e-42,  7.1466e-44,  ...,  7.5232e-37,\n",
       "           8.4078e-45,  4.1085e-40],\n",
       "         [ 4.3087e-41,  1.3008e-39,  1.4599e-36,  ...,  1.4615e-39,\n",
       "           1.9269e-34,  1.1210e-43],\n",
       "         ...,\n",
       "         [ 2.1366e-34,  8.9683e-44,  1.5141e-13,  ...,  1.4013e-45,\n",
       "           6.7625e-33,  1.1749e-37],\n",
       "         [ 1.4486e-39,  3.8500e-34,  3.5873e-43,  ...,  1.2879e-39,\n",
       "           0.0000e+00,  4.1084e-40],\n",
       "         [ 1.5496e-13,  1.4493e-39,  3.8500e-34,  ...,  1.4586e-39,\n",
       "           2.7927e-39,  0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.0434e-37,  3.5733e-43,  2.2717e-40,  ...,  6.4542e-10,\n",
       "           7.7146e+31,  7.0809e+31],\n",
       "         [ 1.4593e-39,  2.1366e-34,  0.0000e+00,  ...,  6.4097e-10,\n",
       "           8.8924e-10,  2.8351e+03],\n",
       "         [ 7.0243e-30,  1.4593e-39,  7.5232e-37,  ...,  1.5434e+25,\n",
       "           5.0844e-08,  3.4661e+27],\n",
       "         ...,\n",
       "         [ 3.8500e-34,  1.9618e-44,  3.3225e-29,  ...,  1.0023e+12,\n",
       "           1.0320e-08,  2.8699e+32],\n",
       "         [ 1.4586e-39,  7.1466e-44,  1.4013e-45,  ...,  2.9188e-11,\n",
       "           4.4756e+27,  4.5630e+30],\n",
       "         [-2.3852e+38,  1.3207e-38,  3.8500e-34,  ...,  3.2183e+21,\n",
       "           3.0376e+29,  9.3146e-39]],\n",
       "\n",
       "        [[ 1.1095e+27,  1.1628e+27,  1.0645e+24,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 6.7347e+22,  1.6529e+19,  4.1317e-08,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.6678e+19,  4.5080e+21,  1.0003e+33,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 1.7541e+19,  5.1695e+07,  5.5623e-05,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.8754e+28,  2.7347e+20,  3.3949e-09,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 6.9146e+28,  1.6244e+19,  6.4097e-10,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.4593e-39,\n",
       "           2.7927e-39,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.6664e-32,\n",
       "           2.8132e-39,  7.5232e-37],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  8.4078e-45,\n",
       "           4.1085e-40,  1.4615e-39],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.4615e-39,\n",
       "           1.1285e-36,  1.4013e-45],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.1664e-34,\n",
       "           1.0573e-37,  4.4832e-38],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           4.1084e-40,  1.4586e-39]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_feature_.squeeze_(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 23, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_feature_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
